<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-video/AV1" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">AV1 | Codec Wiki</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wiki.x266.mov/img/codec-wiki-social-card.webp"><meta data-rh="true" name="twitter:image" content="https://wiki.x266.mov/img/codec-wiki-social-card.webp"><meta data-rh="true" property="og:url" content="https://wiki.x266.mov/docs/video/AV1"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="AV1 | Codec Wiki"><meta data-rh="true" name="description" content="AV1 is a royalty-free video compression format designed to succeed VP9. It presently competes with VP9, VVC, and HEVC. AV1 is computationally more complex than VP9, but is fast to decode due to the mature and efficient dav1d AV1 decoder. AV1 hardware accelerated decoding is also available on a variety of different consumer hardware devices, all of which are enumerated on Wikipedia. Standout entries include modern Intel, AMD, &amp; Nvidia integrated &amp; discrete GPUs, Google&#x27;s Tensor SoC powering the Pixel line, Apple&#x27;s A17 Pro in the iPhone 15 Pro series, and modern Mediatek &amp; Qualcomm chips. YouTube is currently in the process of transitioning their videos to use AV1."><meta data-rh="true" property="og:description" content="AV1 is a royalty-free video compression format designed to succeed VP9. It presently competes with VP9, VVC, and HEVC. AV1 is computationally more complex than VP9, but is fast to decode due to the mature and efficient dav1d AV1 decoder. AV1 hardware accelerated decoding is also available on a variety of different consumer hardware devices, all of which are enumerated on Wikipedia. Standout entries include modern Intel, AMD, &amp; Nvidia integrated &amp; discrete GPUs, Google&#x27;s Tensor SoC powering the Pixel line, Apple&#x27;s A17 Pro in the iPhone 15 Pro series, and modern Mediatek &amp; Qualcomm chips. YouTube is currently in the process of transitioning their videos to use AV1."><link data-rh="true" rel="icon" href="/img/favicon.svg"><link data-rh="true" rel="canonical" href="https://wiki.x266.mov/docs/video/AV1"><link data-rh="true" rel="alternate" href="https://wiki.x266.mov/docs/video/AV1" hreflang="en"><link data-rh="true" rel="alternate" href="https://wiki.x266.mov/docs/video/AV1" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Codec Wiki RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Codec Wiki Atom Feed">






<link rel="preload" href="static/fonts/Inter.var.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="static/fonts/Mona-Sans.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="static/fonts/Monaspace-Neon.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous">
<script src="https://analytics.x266.mov/js/script.js" defer="defer" data-domain="wiki.x266.mov"></script><link rel="stylesheet" href="/assets/css/styles.1ebb109b.css">
<script src="/assets/js/runtime~main.2d366841.js" defer="defer"></script>
<script src="/assets/js/main.f8dfb801.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.svg" alt="AV1 &quot;Stonks&quot; logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.svg" alt="AV1 &quot;Stonks&quot; logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Codec Wiki</b></a><a class="navbar__item navbar__link" href="/docs/introduction/prologue">Get Started</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://discord.gg/bbQD5MjDr3" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-discord-link" aria-label="Discord"></a><a href="https://github.com/av1-community-contributors/codec-wiki/tree/main" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub"></a><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/introduction/prologue">üí° Introduction</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/audio/intro">üîä Audio</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/video/AVC">üìπÔ∏è Video</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/AVC">AVC / H.264</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/HEVC">HEVC / H.265</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/VVC">VVC / H.266</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/VP8">VP8</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/VP9">VP9</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/video/AV1">AV1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/AVS3">AVS3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/VC-1">VC-1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/Theora">Theora</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/FFV1">FFV1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/utvideo">UT Video</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/prores">ProRes</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/video/ECM">ECM</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/data/zip">üíΩ Data</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/images/JPEG">üèûÔ∏è Images</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/encoders/x264">üíæ Encoders</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/encoders_hw/nvenc">üöÄ Hardware Encoders</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/subtitles/SRT">üí¨ Subtitles</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/filtering/vapoursynth">üéûÔ∏è Filtering</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/colorimetry/intro">üé® Colorimetry</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/utilities/Aviator">üõ†Ô∏è Utilities</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/metrics/PSNR">üëÅÔ∏è Metrics</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/video-players">‚ñ∂Ô∏è Video Players</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/resources">üóÉÔ∏è Resources</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/contribution-guide">‚úíÔ∏è Contribution Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/FAQ">‚ùì FAQ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/privacy-policy">üîè Privacy Policy</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/terms-of-use">ü§ù Terms of Use</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">üìπÔ∏è Video</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">AV1</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>AV1</h1></header>
<p>AV1 is a royalty-free video compression format designed to succeed <a href="/docs/video/VP9">VP9</a>. It presently competes with <a href="/docs/video/VP9">VP9</a>, <a href="/docs/video/VVC">VVC</a>, and <a href="/docs/video/HEVC">HEVC</a>. AV1 is computationally more complex than VP9, but is fast to decode due to the mature and efficient dav1d AV1 decoder. AV1 hardware accelerated decoding is also available on a variety of different consumer hardware devices, all of which are enumerated <a href="https://en.wikipedia.org/wiki/AV1#Hardware" target="_blank" rel="noopener noreferrer">on Wikipedia</a>. Standout entries include modern Intel, AMD, &amp; Nvidia integrated &amp; discrete GPUs, Google&#x27;s Tensor SoC powering the Pixel line, Apple&#x27;s A17 Pro in the iPhone 15 Pro series, and modern Mediatek &amp; Qualcomm chips. YouTube is currently in the process of transitioning their videos to use AV1.</p>
<p>There are a number of viable AV1 encoding solutions available today. The three best, most ubiquitous, and free implementations are <a href="/docs/encoders/aomenc">aomenc</a>, <a href="/docs/encoders/SVT-AV1">SVT-AV1</a>, &amp; <a href="/docs/encoders/rav1e">rav1e</a>.</p>
<h1>A Technical Overview of AV1</h1>
<p><em>This section has been graciously borrowed from Qu Pengfei&#x27;s amazing <a href="https://github.com/QuPengfei/Technical-Overview-Of-AV1-Spec/blob/master/README.md" target="_blank" rel="noopener noreferrer">AV1 README.md</a>, with some minor grammar, formatting, and spelling corrections. Thank you, Qu Pengfei!</em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract<a href="#abstract" class="hash-link" aria-label="Direct link to Abstract" title="Direct link to Abstract">‚Äã</a></h2>
<p>AV1 (AOMedia Video Codec 1.0) evolved on the basis of VP9 (Google), Thor (Cisco)
and Daala (Mozila) under the AOM (Alliance for Open Media). It includes a number
of enhancement and the new tools that have been added to improve the coding
efficiency. The new tools that are added so far include 4 main aspects:
prediction, transform, in-loop filter and entropy encoder. This document
provides a snapshot of the coding tools in the current finalized version (on
March, 2018) of AV1 spec.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">‚Äã</a></h2>
<p>According to the AOM web page, AV1 is designed with the following feature.</p>
<ul>
<li>
<p>Royally free</p>
</li>
<li>
<p>Scales to any modern device at any bandwidth</p>
</li>
<li>
<p>For use in both commercial and non-commercial content, including
user-generated content</p>
</li>
<li>
<p>Developed for the internet and related applications and services-from
browsers and streaming to videoconferencing services</p>
</li>
<li>
<p>Designed with a low computational footprint and optimized for hardware</p>
</li>
<li>
<p>Bringing features like 4k UHD, HDR, and WCG to real-time video</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="profile--levels">Profile &amp; Levels<a href="#profile--levels" class="hash-link" aria-label="Direct link to Profile &amp; Levels" title="Direct link to Profile &amp; Levels">‚Äã</a></h2>
<p>Profiles and levels specify restrictions on the capabilities needed to decode
the bitstreams. The profile specifies the bit depth and subsampling formats
supported, while the level defines resolution and performance characteristics.
By now levels is still under discussion and there is no more details.</p>
<p>AV1 support the three named profiles as the table list.</p>
<table><thead><tr><th>Profile</th><th>Bit depth</th><th>Monochrome support</th><th>Chroma subsampling</th><th>Name</th></tr></thead><tbody><tr><td>0</td><td>8/10</td><td>Yes</td><td>4:2:0</td><td>Main</td></tr><tr><td>1</td><td>8/10</td><td>No</td><td>4:4:4</td><td>High</td></tr><tr><td>2</td><td>8/10</td><td>Yes</td><td>4:2:2</td><td>Professional</td></tr><tr><td>2</td><td>12</td><td>Yes</td><td>4:2:0, 4:2:2, 4:4:4</td><td>Professional</td></tr></tbody></table>
<p>Table 1. AV1 Profile</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="block-structure">Block Structure<a href="#block-structure" class="hash-link" aria-label="Direct link to Block Structure" title="Direct link to Block Structure">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-coding-block">Basic Coding block<a href="#basic-coding-block" class="hash-link" aria-label="Direct link to Basic Coding block" title="Direct link to Basic Coding block">‚Äã</a></h3>
<p>AV1 support the larger super block size, which is up to 128x128 super block is
allowed. It supports from 128x128 down to 4x4 coding block. Each 4x4 luma block
is allowed to independently select inter or intra mode, its reference mode, and
interpolation filter type. For Chroma, 2x2 block size is allowed but still 4x4
transform block size is used.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-prediction-block">Basic Prediction Block<a href="#basic-prediction-block" class="hash-link" aria-label="Direct link to Basic Prediction Block" title="Direct link to Basic Prediction Block">‚Äã</a></h3>
<p>AV1 support up to 10 partition type. The size of partition unit is allowed down
to 4x4 and totally there are 24 types of block size.</p>
<table><thead><tr><th>Partition index</th><th>Type of partition</th></tr></thead><tbody><tr><td>0</td><td>PARTITION_NONE</td></tr><tr><td>1</td><td>PARTITION_HORZ</td></tr><tr><td>2</td><td>PARTITION_VERT</td></tr><tr><td>3</td><td>PARTITION_SPLIT</td></tr><tr><td>4</td><td>PARTITION_HORZ_A</td></tr><tr><td>5</td><td>PARTITION_HORZ_B</td></tr><tr><td>6</td><td>PARTITION_VERT_A</td></tr><tr><td>7</td><td>PARTITION_VERT_B</td></tr><tr><td>8</td><td>PARTITION_HORZ_4</td></tr><tr><td>9</td><td>PARTITION_VERT_4</td></tr></tbody></table>
<p>Table 2. Type of Block partition</p>
<table><thead><tr><th>Index</th><th>Partition Block size</th><th>Index</th><th>Partition Block size</th></tr></thead><tbody><tr><td>0</td><td>BLOCK_4X4</td><td>12</td><td>BLOCK_64X64</td></tr><tr><td>1</td><td>BLOCK_4X8</td><td>13</td><td>BLOCK_64X128</td></tr><tr><td>2</td><td>BLOCK_8X4</td><td>14</td><td>BLOCK_128X64</td></tr><tr><td>3</td><td>BLOCK_8X8</td><td>15</td><td>BLOCK_128X128</td></tr><tr><td>4</td><td>BLOCK_8X16</td><td>16</td><td>BLOCK_4X16</td></tr><tr><td>5</td><td>BLOCK_16X8</td><td>17</td><td>BLOCK_16X4</td></tr><tr><td>6</td><td>BLOCK_16X16</td><td>18</td><td>BLOCK_8X32</td></tr><tr><td>7</td><td>BLOCK_16X32</td><td>19</td><td>BLOCK_32X8</td></tr><tr><td>8</td><td>BLOCK_32X16</td><td>20</td><td>BLOCK_16X64</td></tr><tr><td>9</td><td>BLOCK_32X32</td><td>21</td><td>BLOCK_64X16</td></tr><tr><td>10</td><td>BLOCK_32X64</td><td>22</td><td>BLOCK_32X128</td></tr><tr><td>11</td><td>BLOCK_64X32</td><td>23</td><td>BLOCK_128X32</td></tr></tbody></table>
<p>Table 3. Size of Block Partition</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-transform-block">Basic Transform Block<a href="#basic-transform-block" class="hash-link" aria-label="Direct link to Basic Transform Block" title="Direct link to Basic Transform Block">‚Äã</a></h3>
<p>Both square and rectangle transform block size is supported in AV1. There are
total 19 transform block size.</p>
<table><thead><tr><th>Index</th><th>TxSize</th><th>Index</th><th>TxSize</th></tr></thead><tbody><tr><td>0</td><td>TX_4X4</td><td>10</td><td>TX_32X16</td></tr><tr><td>1</td><td>TX_8X8</td><td>11</td><td>TX_32X64</td></tr><tr><td>2</td><td>TX_16X16</td><td>12</td><td>TX_64X32</td></tr><tr><td>3</td><td>TX_32X32</td><td>13</td><td>TX_4X16</td></tr><tr><td>4</td><td>TX_64X64</td><td>14</td><td>TX_16X4</td></tr><tr><td>5</td><td>TX_4X8</td><td>15</td><td>TX_8X32</td></tr><tr><td>6</td><td>TX_8X4</td><td>16</td><td>TX_32X8</td></tr><tr><td>7</td><td>TX_8X16</td><td>17</td><td>TX_16X64</td></tr><tr><td>8</td><td>TX_16X8</td><td>18</td><td>TX_64X16</td></tr><tr><td>9</td><td>TX_16X32</td><td></td><td></td></tr></tbody></table>
<blockquote>
<p>Table 4. Size of Transform Block</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="intra-prediction">Intra Prediction<a href="#intra-prediction" class="hash-link" aria-label="Direct link to Intra Prediction" title="Direct link to Intra Prediction">‚Äã</a></h2>
<p>Intra Prediction in AV1 expends largely compared to VP9. Here is snapshot of
Intra Mode.</p>
<table><thead><tr><th>Index</th><th>Intra mode</th><th>AV1</th><th>VP9</th><th>Comments</th></tr></thead><tbody><tr><td>0</td><td>DC_PRED</td><td>X</td><td>X</td><td></td></tr><tr><td>1</td><td>V_PRED</td><td>X</td><td>X</td><td>AV1 support 7 kind of mode based on this mode</td></tr><tr><td>2</td><td>H_PRED</td><td>X</td><td>X</td><td>AV1 support 7 kind of mode based on this mode</td></tr><tr><td>3</td><td>D45_PRED</td><td>X</td><td>X</td><td>AV1 support 7 kind of mode based on this mode</td></tr><tr><td>4</td><td>D135_PRED</td><td>X</td><td>X</td><td>AV1 support 7 kind of mode based on this mode</td></tr><tr><td>5</td><td>D113_PRED</td><td>X</td><td>X</td><td>AV1 support 7 kind of mode based on this mode</td></tr><tr><td>6</td><td>D157_PRED</td><td>X</td><td>X</td><td>AV1 support 7 kind of mode based on this mode</td></tr><tr><td>7</td><td>D203_PRED</td><td>X</td><td>X</td><td>AV1 support 7 kind of mode based on this mode</td></tr><tr><td>8</td><td>D67_PRED</td><td>X</td><td>X</td><td>AV1 support 7 kind of mode based on this mode</td></tr><tr><td>9</td><td>SMOOTH_PRED</td><td>X</td><td></td><td></td></tr><tr><td>10</td><td>SMOOTH_V_PRED</td><td>X</td><td></td><td></td></tr><tr><td>11</td><td>SMOOTH_H_PRED</td><td>X</td><td></td><td></td></tr><tr><td>12</td><td>TM_PRED(PAETH_PRED)</td><td>X</td><td>X</td><td>AV1 replace TM_PRED with PAETH_PRED</td></tr><tr><td>13</td><td>Palette Mode</td><td>X</td><td></td><td></td></tr></tbody></table>
<p>Table 5. Summary of Intra Mode between AV1 and VP9</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="directional-intra-prediction-mode">Directional Intra Prediction Mode<a href="#directional-intra-prediction-mode" class="hash-link" aria-label="Direct link to Directional Intra Prediction Mode" title="Direct link to Directional Intra Prediction Mode">‚Äã</a></h3>
<p>VP9 only supports 8 directional intra prediction modes: D45_PRED, D63_PRED,
H_PRED, D117_PRED, D135_PRED, D153_PRED, V_PRED, D207_PRED. These modes
correspond to prediction angles of 45, 63, 90, 117, 135, 153, 180, and 207
degrees, respectively.</p>
<p>To improve intra coding efficiency, more prediction angle options are added to
AV1. The prediction angle is calculated as the following:</p>
<p>Prediction angle = nominal_angle + (angle_delta * angle_step),</p>
<table><thead><tr><th>nominal_angle</th><th>angle_step</th><th>angle_delta</th><th>Total number of angles</th></tr></thead><tbody><tr><td>45, 63, 90, 117, 135, 153, 180, 207</td><td>3</td><td>[-3, +3]</td><td>8*7=56</td></tr></tbody></table>
<p>Table 6. Finer of Intra Mode</p>
<ul>
<li>
<p>norminal_angle is determined by the prediction mode, and is the same as VP9;</p>
</li>
<li>
<p>angle_delta is in a predefined range and angle_step is a predefined value.
In current configuration, angle_delta is in the range of [-3, +3] and
angle_step is 3. These settings are selected experimentally.</p>
</li>
<li>
<p>The total number of supported prediction angles is therefore increased from
8 to 8 * 7 = 56.</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="smooth-mode">Smooth Mode<a href="#smooth-mode" class="hash-link" aria-label="Direct link to Smooth Mode" title="Direct link to Smooth Mode">‚Äã</a></h3>
<p>It is a Non- Directional Intra Prediction mode. VP9 has 2 non-directional intra
prediction modes: DC_PRED and TM_PRED. AV1 expands on this by adding 3 new
smooth prediction modes: SMOOTH_PRED, SMOOTH_V_PRED and SMOOTH_H_PRED. The new
modes work as follows:</p>
<table><thead><tr><th>Mode</th><th>Comments</th></tr></thead><tbody><tr><td>SMOOTH_PRED</td><td>Useful for predicting blocks that have a smooth gradient. It works as follows: estimate the pixels on the rightmost column with the value of the last pixel in top row, and estimate the pixels in the last row of the current block using the last pixel in left column. Then calculate the rest of the pixels by an average of quadratic interpolation in vertical and horizontal directions, based on distance of the pixel from the predicted pixels.</td></tr><tr><td>SMOOTH_V_PRED</td><td>Similar to SMOOTH_PRED, but uses quadratic interpolation only in the vertical direction</td></tr><tr><td>SMOOTH_H_PRED</td><td>Similar to SMOOTH_PRED, but uses quadratic interpolation only in the horizontal direction</td></tr></tbody></table>
<p>Table 7. Smooth mode of Intra mode</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="paeth-mode">Paeth Mode<a href="#paeth-mode" class="hash-link" aria-label="Direct link to Paeth Mode" title="Direct link to Paeth Mode">‚Äã</a></h3>
<p>It is a Non- Directional Intra Prediction mode. The new prediction mode
PAETH_PRED replaces the existing mode TM_PRED.</p>
<p>TM_PRED: Predictor(TM) = left + top ‚Äì top_left</p>
<p>PAETH_PRED: Predictor (PAETH) = argmin |x- Predictor(TM)|</p>
<p>The idea is to find out the One of left, top, top_left closest in value to
Predictor(TM).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="palette-mode">Palette Mode<a href="#palette-mode" class="hash-link" aria-label="Direct link to Palette Mode" title="Direct link to Palette Mode">‚Äã</a></h3>
<p>Sometimes, given intra block can be approximated by a block with small number of
unique colors. This is especially true for artificial videos like
screen-capture, games etc. For such cases, AV1 introduces a new intra coding
mode called palette mode. This predictor for a block is signaled by storing (i)
a color palette, with 2 to 8 colors, and (ii) color indices into the palette for
all pixels in the block. The residual pixel values of the block are as usual
transformed and quantized before being entropy-coded.</p>
<p>Palette mode can be used by both intra-only as well as inter frames. The number
of base colors determines the trade-off between fidelity and compactness. The
color indices for pixels are obtained by the nearest neighbor method. The color
indices are encoded using the neighborhood-based context to be as compact as
possible.</p>
<p>Palette Mode is not new. We can see the Palette Mode and Intra block copy in the
HEVC SCC (Screen Content Coding) extension.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="filter-intra-mode">Filter Intra mode<a href="#filter-intra-mode" class="hash-link" aria-label="Direct link to Filter Intra mode" title="Direct link to Filter Intra mode">‚Äã</a></h3>
<p>AV1 adopt the new mode to interpolate (intra filter) the reference samples
before prediction. This will reduce the impact of quantization noise. Here is
the table to specify the type of intra filtering.</p>
<table><thead><tr><th>Index</th><th>Filter intra type</th></tr></thead><tbody><tr><td>0</td><td>INTRA_DC_PRED</td></tr><tr><td>1</td><td>INTRA_V_PRED</td></tr><tr><td>2</td><td>INTRA_H_PRED</td></tr><tr><td>3</td><td>INTRA_D153_PRED</td></tr><tr><td>4</td><td>INTRA_TM_PRED</td></tr></tbody></table>
<p>Table 8 Type of Intra filter Mode</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="intra-block-copy-mode">Intra Block Copy Mode<a href="#intra-block-copy-mode" class="hash-link" aria-label="Direct link to Intra Block Copy Mode" title="Direct link to Intra Block Copy Mode">‚Äã</a></h3>
<p>This tool is very efficient for coding of screen content video in that repeated
patterns in text and graphics rich content occur frequently within the same
picture. Having a previously reconstructed block with equal or similar pattern
as a predictor can effectively reduce the prediction error and therefore improve
coding efficiency.</p>
<p>In AV1, Intra block copy is only allowed in intra frames. It disables all loop
filtering and only integer offsets are allowed in block copy mode.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="predict-chroma-from-luma">Predict Chroma from Luma<a href="#predict-chroma-from-luma" class="hash-link" aria-label="Direct link to Predict Chroma from Luma" title="Direct link to Predict Chroma from Luma">‚Äã</a></h3>
<p>Chroma from luma (CfL) prediction is a new and promising chroma-only intra
predictor that models chroma pixels as a linear function of the coincident
reconstructed luma pixels.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="inter-prediction">Inter Prediction<a href="#inter-prediction" class="hash-link" aria-label="Direct link to Inter Prediction" title="Direct link to Inter Prediction">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="affinewarped-motion-compensation">Affine/Warped Motion Compensation<a href="#affinewarped-motion-compensation" class="hash-link" aria-label="Direct link to Affine/Warped Motion Compensation" title="Direct link to Affine/Warped Motion Compensation">‚Äã</a></h3>
<p>Traditional modern codecs, including VP9, use block motion compensation where
motion vectors are translational only. This is not sufficient for real video
which often contains complex motion. For example, motion due to camera shake,
panning and zoom might require transformations that support shearing, scaling,
rotation and changes in aspect ratio. In AV1, we introduce warped motion
compensation implemented as similarity and affine transformations to better
capture the diversity of motion that exists in real video. There are two
affine/warped motion compensation.</p>
<table><thead><tr><th>Affine Motion Compensation</th><th>Comments</th></tr></thead><tbody><tr><td>Global</td><td>It is common for videos to contain a global camera motion which is pertinent to an entire inter frame. It is therefore beneficial to transmit a set of motion parameters at the frame level that is applicable to a large number of blocks in the frame. When a frame is encoded, a set of global motion parameters is computed and transmitted between that frame and each reference frame. These parameters may be either translational, similarity or affine motion model. Subsequently, any block in the frame can signal use of the global motion mode with a given reference to create a suitable predictor.</td></tr><tr><td>Local</td><td>Affine motion compensation is also useful to describe complex local object motion. Here, we estimate affine parameters for a single block using the translational motion vectors that are typically conveyed for all inter blocks. Specifically, we estimate an affine or similarity model using the motion vectors from the current block and its causal neighbors which share the same reference frame.</td></tr></tbody></table>
<p>Table 9 Affine Motion Compensation</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="obmc-overlapped-block-motion-compensation">OBMC (Overlapped Block Motion Compensation)<a href="#obmc-overlapped-block-motion-compensation" class="hash-link" aria-label="Direct link to OBMC (Overlapped Block Motion Compensation)" title="Direct link to OBMC (Overlapped Block Motion Compensation)">‚Äã</a></h3>
<p>Motions assigned to surrounding blocks will contribute to predicting a current
block, via a well-defined overlapping scheme appropriately designed for advanced
variable block-size partitioning frameworks.</p>
<p>The OBMC will blend multiple predictors from neighbor blocks. It is not new
concept and was proposed and implemented back in the era of h.263. The OBMC was
proved to largely reduce prediction errors but not adopted by recent codecs due
to extra complexity in the scenario of hybrid inter/intra variable block size
coding. In AV1, a practical overlapping mechanism based on two-stage 1-D
filtering is proposed for the advanced partitioning framework to implement
causal overlapped block prediction.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sub-pixel-interpolation-filter">Sub-pixel Interpolation Filter<a href="#sub-pixel-interpolation-filter" class="hash-link" aria-label="Direct link to Sub-pixel Interpolation Filter" title="Direct link to Sub-pixel Interpolation Filter">‚Äã</a></h3>
<p>The motion vector used in modern video codecs is allowed to have a fractional
position for a better prediction quality. So, an interpolation filter module is
needed to generate the prediction block at a fractional position in the
reference frame. VP9 codec uses a separable interpolation filter to perform
inter prediction with ‚Öõ motion vector precision. Three filter types, SHARP,
REGULAR and SMOOTH, in descending order of cutoff frequencies, are provided to
deal with various types of noise/distortions that can occur in reference
frames/blocks. Given a filter type and a motion vector, the interpolation filter
is performed by two one-dimensional filters, one for horizontal direction and
one for vertical direction.</p>
<p>In AV1 codec, dual interpolation filter is introduced on top of the
interpolation module inherited from VP9. Dual filter allows each block/frame to
use a different interpolation filter type in horizontal and vertical direction.
Up to 9 types of filter will be applied to the block.</p>
<p>This idea is based on the observation that a reference frame/block‚Äôs horizontal
and vertical signals may have distinct frequency characteristics; therefore,
using different filter types may produce a better prediction. As before, both
the filter types are transmitted in the bitstream on a per block or per frame
basis.</p>
<p>At the same time AV1 use the high intermediate precision between the horizontal
and vertical filter. The same high precision before average the predictors with
compound mode.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dynamic-mv-reference">Dynamic MV reference<a href="#dynamic-mv-reference" class="hash-link" aria-label="Direct link to Dynamic MV reference" title="Direct link to Dynamic MV reference">‚Äã</a></h3>
<p>VP9 has two candidates MV in the ref list and 4 type of mode (NEARESTMV, NEARMV,
NEWMV, and ZEROMV) are used. AV1 support 4 candidate MV and more modes.</p>
<p>For single ref mode, AV1 is same as VP9.</p>
<p>For compound mode, VP9 restricts motion vectors for a compound predictor to
share one motion vector referencing mode, even though they may use different
reference frames. To add more flexibility, on top of existing four combinations
(NEAREST_NEARESTMV, NEAR_NEARMV, NEW_NEWMV, ZERO_ZEROMV) in VP9, AV1 supports
four more empirically selected combinations: NEAREST_NEWMV, NEW_NEARESTMV,
NEAR_NEWMV, and NEW_NEARMV.</p>
<table><thead><tr><th>Index</th><th>Type</th><th>Ref Mode</th></tr></thead><tbody><tr><td>0</td><td>NEARESTMV</td><td>single ref mode</td></tr><tr><td>1</td><td>NEARMV</td><td>single ref mode</td></tr><tr><td>2</td><td>GLOBALMV(ZEROMV)</td><td>single ref mode</td></tr><tr><td>3</td><td>NEWMV</td><td>single ref mode</td></tr><tr><td>4</td><td>NEAREST_NEARESTMV</td><td>compound mode</td></tr><tr><td>5</td><td>NEAR_NEARMV</td><td>compound mode</td></tr><tr><td>6</td><td>NEAREST_NEWMV</td><td>compound mode</td></tr><tr><td>7</td><td>NEW_NEARESTMV</td><td>compound mode</td></tr><tr><td>8</td><td>NEAR_NEWMV</td><td>compound mode</td></tr><tr><td>9</td><td>NEW_NEARMV</td><td>compound mode</td></tr><tr><td>10</td><td>GLOBAL_GLOBALMV(ZERO_ZEROMV)</td><td>compound mode</td></tr><tr><td>11</td><td>NEW_NEWMV</td><td>compound mode</td></tr></tbody></table>
<p>Table 10 MV mode</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="extended-compound-modes">Extended Compound Modes<a href="#extended-compound-modes" class="hash-link" aria-label="Direct link to Extended Compound Modes" title="Direct link to Extended Compound Modes">‚Äã</a></h3>
<p>AV1 Compound mode support both predictors from the same direction and VP9 only
support from the different direction (One forward and one backward reference
frame). VP9 only support 1/2 weight to blend the two predictor and AV1 support
more flexible weight blending.</p>
<table><thead><tr><th>Index</th><th>Compound type</th><th>Comments</th></tr></thead><tbody><tr><td>0</td><td>COMPOUND_WEDGE</td><td>Inter-Inter Wedge mode Inter-Intra Wedge mode</td></tr><tr><td>1</td><td>COMPOUND_SEG</td><td>Inter-Inter Compound Segment mode</td></tr><tr><td>2</td><td>COMPOUND_AVERAGE</td><td>(1/2,1/2) weight will be applied to blend the predictors</td></tr><tr><td>3</td><td>COMPOUND_INTRA</td><td>Inter-Intra Gradual mode</td></tr><tr><td>4</td><td>COMPOUND_DISTANCE</td><td>This process computes weights to be used for blending predictions together based on the expected output times of the reference frames</td></tr></tbody></table>
<p>Table 11. Compound type</p>
<p>Here are more details about the Compound Segment Mode:</p>
<ul>
<li>Inter-Inter Compound Segment mode</li>
</ul>
<p>In many cases, regions in one predictor will contain useful content that is not
present in the other. The two inter predictors have a larger pixel difference
generally.</p>
<ul>
<li>Inter-Inter Wedge mode</li>
</ul>
<p>Boundaries of moving objects in a video often separate two regions with distinct
motions. Coding these regions with separate motion vector reference combinations
should be beneficial; however, finding exact object boundaries is not only
difficult, but expensive to communicate in the bitstream. Our approach is to
design a codebook of masks with only a few possible partitioning combinations
and signaling the codebook index in the bitstream.</p>
<p>The AV1 wedge codebook contains partition orientations that are either
horizontal, vertical or oblique with slopes: 2, -2, 0.5 and -0.5. The wedge
prediction mode is used for all square and rectangular blocks, using the 16-ary
shape codebooks.</p>
<table><thead><tr><th>Index</th><th>Wedge direction</th><th>Comments</th></tr></thead><tbody><tr><td>0</td><td>WEDGE_HORIZONTAL</td><td></td></tr><tr><td>1</td><td>WEDGE_VERTICAL</td><td></td></tr><tr><td>2</td><td>WEDGE_OBLIQUE27</td><td></td></tr><tr><td>3</td><td>WEDGE_OBLIQUE63</td><td></td></tr><tr><td>4</td><td>WEDGE_OBLIQUE117</td><td></td></tr><tr><td>5</td><td>WEDGE_OBLIQUE153</td><td></td></tr></tbody></table>
<p>Table 12. Wedge direction</p>
<ul>
<li>Inter-Intra Gradual mode</li>
</ul>
<p>Decay the weight gradually for the intra from the prediction boundary and
increase the weight of inter correspondingly. It support four modes, which
include horizontal mode, vertical mode, DC_PRED, and SMOOTH_PRED.</p>
<ul>
<li>Inter-Intra Wedge mode</li>
</ul>
<p>Blocks cannot always perfectly partition moving objects. For example, occlusion
can occur in the middle of a block, it is better to apply different prediction
techniques to different contents. Contents that are not occluded in reference
frame will prefer inter prediction, while newly revealed content could benefit
more from intra prediction using local reference.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="extended-reference-frame-number">Extended Reference frame Number<a href="#extended-reference-frame-number" class="hash-link" aria-label="Direct link to Extended Reference frame Number" title="Direct link to Extended Reference frame Number">‚Äã</a></h3>
<p>Up to 7 reference frames out of 8 in the frame stored buffer are extended to be
used in the inter mode. The reference frames is allowed to come from the same
side or different side in the AV1.</p>
<p>LAST3_FRAME, LAST2_FRAME and LAST_FRAME are forward references and LAST_FRAME is
the near past frame. BWDREF_FRAME is a backward reference, similar to
ALTREF_FRAME.</p>
<p>Here is the table to show the reference frame type.</p>
<table><thead><tr><th>Index</th><th>Ref frame Name</th></tr></thead><tbody><tr><td>0</td><td>INTRA_FRAME</td></tr><tr><td>1</td><td>LAST_FRAME</td></tr><tr><td>2</td><td>LAST2_FRAME</td></tr><tr><td>3</td><td>LAST3_FRAME</td></tr><tr><td>4</td><td>GOLDEN_FRAME</td></tr><tr><td>5</td><td>BWDREF_FRAME</td></tr><tr><td>6</td><td>ALTREF2_FRAME</td></tr><tr><td>7</td><td>ALTREF_FRAME</td></tr></tbody></table>
<p>Table 13 Reference frame type</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="in-loop-filter">In-loop Filter<a href="#in-loop-filter" class="hash-link" aria-label="Direct link to In-loop Filter" title="Direct link to In-loop Filter">‚Äã</a></h2>
<p>Several in-loop tools in AV1 are employed. De-blocking, CDEF and loop
restoration are cascaded.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="de-blocking-filter">De-blocking filter<a href="#de-blocking-filter" class="hash-link" aria-label="Direct link to De-blocking filter" title="Direct link to De-blocking filter">‚Äã</a></h3>
<p>AV1 support 4 filter levels per frame and VP9 only has one. Two levels are for
Luma component (horizontal and vertical levels). The other two levels are for U
and V component separately. In AV1, filter level is allowed to change superblock
by superblock.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cdef-constrained-directional-enhancement-filter">CDEF (Constrained Directional Enhancement Filter)<a href="#cdef-constrained-directional-enhancement-filter" class="hash-link" aria-label="Direct link to CDEF (Constrained Directional Enhancement Filter)" title="Direct link to CDEF (Constrained Directional Enhancement Filter)">‚Äã</a></h3>
<p>CDEF is the combination of CLPF (Constrained Low Pass Filter) and Deringing
filter. The main goal of the in-loop CEDF is to filter the coding artifacts and
ringing while preserving the detail of image. It takes into account the
direction of edge and patterns in the image. It is the similar to the SAO of
HEVC.</p>
<p>The CDEF is based on the following observation. The amount of ringing artifacts
in a coded image tends to be roughly proportional to the quantization step size.
The amount of detail is a property of the input image, but the smallest detail
actually retained in the quantized image tends to also be proportional to the
quantization step size. For a given quantization step size, the amplitude of the
ringing is generally less than the amplitude of the details.</p>
<p>CDEF works as the following steps:</p>
<ul>
<li>
<p>The frame is divided into filter blocks of 64x64 pixels. Some CDEF
parameters are signaled at the frame level, and some may be signaled at the
filter block level.</p>
</li>
<li>
<p>To identify the direction of edge or pattern in each filter block.</p>
</li>
<li>
<p>To adaptively filter along the identified direction and to a lesser degree
along directions rotated 45 degrees from the identified direction. The
filter strengths are signaled explicitly, which allows a high degree of
control over the blurring.</p>
</li>
</ul>
<p>The main reason for identifying the direction is to align the filter taps along
that direction to reduce ringing while preserving the directional edges or
patterns. CDEF defines primary taps and secondary taps filter. The primary taps
follow the direction and the secondary taps form a cross, oriented 45 off the
direction. Both primary and secondary taps filter have 8 types.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lr-in-loop-restoration-filter">LR (In-loop Restoration) filter<a href="#lr-in-loop-restoration-filter" class="hash-link" aria-label="Direct link to LR (In-loop Restoration) filter" title="Direct link to LR (In-loop Restoration) filter">‚Äã</a></h3>
<p>AV1 employ a set of in-loop image restoration tool after de-blocking to
generally de-noise and enhance the quality of the edge. In-loop restoration
scheme have two types of filter to remove blur artifacts due to block
processing. One is Wiener Filter. The other is Dual Self-Guided filter. These
tools are integrated into AV1 with a switchable framework, which trigger the
different tool in the different image region.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="multi-symbol-entropy-coder">Multi-Symbol Entropy Coder<a href="#multi-symbol-entropy-coder" class="hash-link" aria-label="Direct link to Multi-Symbol Entropy Coder" title="Direct link to Multi-Symbol Entropy Coder">‚Äã</a></h2>
<p>Multi-symbol adaptive arithmetic coding model is adopted in AV1. Both syntax
element and coefficient are coded with this model.</p>
<p>Most recent video codecs encode information using binary arithmetic coding, such
as CABA or CAVLC in AVC/HEVC, meaning that each symbol can only take two values.
The AV1 entropy encoder come from the Daala range coder and supports up to 16
values per symbol, making it possible to encode fewer symbols. This is
equivalent to coding up to four binary values in parallel and reduces serial
dependencies, allowing hardware implementations to use lower clock rates, and
thus less power.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="transform">Transform<a href="#transform" class="hash-link" aria-label="Direct link to Transform" title="Direct link to Transform">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="transform-type">Transform type<a href="#transform-type" class="hash-link" aria-label="Direct link to Transform type" title="Direct link to Transform type">‚Äã</a></h3>
<p>For AV1, there is a richer set of transforms for coding Inter and Intra
prediction residues. Inter prediction residues do not have a well-defined
structure as in the Intra case, but using a bank of transforms, each adapted to
a specific type of residue profile within the block, is generally helpful.</p>
<p>In AV1, four types of transform are used mainly in the horizontal and vertical
direction separately. The total 16 different transforms are available.</p>
<table><thead><tr><th>Transform type</th><th>Comments</th></tr></thead><tbody><tr><td>DCT</td><td>Inter and Intra modes continue to make use of DCT.</td></tr><tr><td>ADST</td><td>Asymmetric Discrete Sine Transform</td></tr><tr><td>Flip ADST</td><td>It applies ADST in reverse order</td></tr><tr><td>IDTX</td><td>Identity transform seems to be particularly useful for coding residue with sharp lines and edges. Identity transform is useful for screen content coding</td></tr></tbody></table>
<p>Table 14 The Main Transform Type in each of direction</p>
<p>For each small coded block (4x4 or 8x8), it is possible to choose one of up to
16 different transforms as follows(Detail in Table):</p>
<p>{DCT, ADST, FlipADST, IDTX} horizontal x {DCT, ADST, FlipADST, IDTX} vertical</p>
<p>As block sizes get larger, some of these transforms begin to act similarly.
Thus, a reduced set of transforms is used for 16x16, 32x32 and 64x64 block
sizes. In the transform selection process for Inter and Intra modes, the encoder
does a search over the entire set of transforms and selects the one that
produces the best rate-distortion cost. Once a transform is selected, a
transform type symbol from the set of types available at that size is used to
indicate the actual transform used in the bitstream.</p>
<p>There are 6 types of transform sets in the AV1 spec, which specify the transform
type of Intra and Inter blocks. The transform sets determine what subset of
transform types can be used, according to the following table.</p>
<table><thead><tr><th>Inter or not</th><th>Set Number</th><th>Transform set</th></tr></thead><tbody><tr><td>Don&#x27;t care</td><td>0</td><td>TX_SET_DCTONLY</td></tr><tr><td>0</td><td>1</td><td>TX_SET_INTRA_1</td></tr><tr><td>0</td><td>2</td><td>TX_SET_INTRA_2</td></tr><tr><td>1</td><td>1</td><td>TX_SET_INTER_1</td></tr><tr><td>1</td><td>2</td><td>TX_SET_INTER_2</td></tr><tr><td>1</td><td>3</td><td>TX_SET_INTER_3</td></tr></tbody></table>
<p>Table 15 Transform Set in the AV1 spec</p>
<table><thead><tr><th>Transform type</th><th>TX_SET_DCTONLY</th><th>TX_SET_INTRA_1</th><th>TX_SET_INTRA_2</th><th>TX_SET_INTER_1</th><th>TX_SET_INTER_2</th></tr></thead><tbody><tr><td>DCT_DCT</td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td></tr><tr><td>ADST_DCT</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td></tr><tr><td>DCT_ADST</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td></tr><tr><td>ADST_ADST</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td></tr><tr><td>FLIPADST_DCT</td><td></td><td></td><td></td><td>X</td><td>X</td></tr><tr><td>DCT_FLIPADST</td><td></td><td></td><td></td><td>X</td><td>X</td></tr><tr><td>FLIPADST_FLIPADST</td><td></td><td></td><td></td><td>X</td><td>X</td></tr><tr><td>ADST_FLIPADST</td><td></td><td></td><td></td><td>X</td><td>X</td></tr><tr><td>FLIPADST_ADST</td><td></td><td></td><td></td><td>X</td><td>X</td></tr><tr><td>IDTX</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td></tr><tr><td>V_DCT</td><td></td><td>X</td><td></td><td>X</td><td>X</td></tr><tr><td>H_DCT</td><td></td><td>X</td><td></td><td>X</td><td>X</td></tr><tr><td>V_ADST</td><td></td><td></td><td></td><td>X</td><td></td></tr><tr><td>H_ADST</td><td></td><td></td><td></td><td>X</td><td></td></tr><tr><td>V_FLIPADST</td><td></td><td></td><td></td><td>X</td><td></td></tr><tr><td>H_FLIPADST</td><td></td><td></td><td></td><td>X</td><td></td></tr></tbody></table>
<p>Table 16 Detailed Transform type supported in each transform set.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="transform-block-shape-and-size">Transform Block Shape and Size<a href="#transform-block-shape-and-size" class="hash-link" aria-label="Direct link to Transform Block Shape and Size" title="Direct link to Transform Block Shape and Size">‚Äã</a></h3>
<p>Both square and rectangle shape block are used in AV1. The transform block size
is less than the partition block size. The block size is very flexible and up to
64x64 and down to 4x4. Details see the table in the Block section.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tiles">Tiles<a href="#tiles" class="hash-link" aria-label="Direct link to Tiles" title="Direct link to Tiles">‚Äã</a></h2>
<p>AV1 support flexible tiles, which include uniform and non-uniform tile spacing.
Tile area is limited to a maximum 4096x2304. Tiles can be grouped into tile
group and each group can be decoded independently to achieve error resilience.
Loop filter can be enabled or disabled across tiles.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="segment">Segment<a href="#segment" class="hash-link" aria-label="Direct link to Segment" title="Direct link to Segment">‚Äã</a></h2>
<p>Same as VP9, AV1 provides a means of segmenting the image and then applying
various adjustments at the segment level. Up to 8 segments may be specified for
any given frame. For each of these segments it is possible to specify:</p>
<ul>
<li>
<p>A quantizer (absolute value or delta).</p>
</li>
<li>
<p>A loop filter strength (absolute value or delta).</p>
</li>
<li>
<p>A prediction reference frame.</p>
</li>
<li>
<p>A block skip mode that implies both the use of a (0,0) motion vector and that
no residual will be coded.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="svc-scalable-video-coding">SVC (Scalable Video Coding)<a href="#svc-scalable-video-coding" class="hash-link" aria-label="Direct link to SVC (Scalable Video Coding)" title="Direct link to SVC (Scalable Video Coding)">‚Äã</a></h2>
<p>AV1 support temporal and spatial layer coding. Temporal layer support up to 8
layers and spatial layer support up to 3 layers.</p>
<table><thead><tr><th>Index</th><th>Scalability mode</th><th>Index</th><th>Scalability mode</th></tr></thead><tbody><tr><td>0</td><td>SCALABILITY_L1T2</td><td>8</td><td>SCALABILITY_L2T2h</td></tr><tr><td>1</td><td>SCALABILITY_L1T3</td><td>9</td><td>SCALABILITY_L2T3h</td></tr><tr><td>2</td><td>SCALABILITY_L2T1</td><td>10</td><td>SCALABILITY_S2T1h</td></tr><tr><td>3</td><td>SCALABILITY_L2T2</td><td>11</td><td>SCALABILITY_S2T2h</td></tr><tr><td>4</td><td>SCALABILITY_L2T3</td><td>12</td><td>SCALABILITY_S2T3h</td></tr><tr><td>5</td><td>SCALABILITY_S2T1</td><td>13</td><td>SCALABILITY_SS</td></tr><tr><td>6</td><td>SCALABILITY_S2T2</td><td>14-255</td><td>reserved</td></tr><tr><td>7</td><td>SCALABILITY_S2T3</td><td></td><td></td></tr></tbody></table>
<p>Table 17. Temporal and Spatial Mode</p>
<table><thead><tr><th>Scalability mode</th><th>Spatial Layers</th><th>Resolution Ratio</th><th>Temporal Layers</th><th>Inter-layer-dependency</th></tr></thead><tbody><tr><td>SCALABILITY_L1T2</td><td>1</td><td></td><td>2</td><td></td></tr><tr><td>SCALABILITY_L1T3</td><td>1</td><td></td><td>3</td><td></td></tr><tr><td>SCALABILITY_L2T1</td><td>2</td><td>2:1</td><td>1</td><td>Yes</td></tr><tr><td>SCALABILITY_L2T2</td><td>2</td><td>2:1</td><td>2</td><td>Yes</td></tr><tr><td>SCALABILITY_L2T3</td><td>2</td><td>2:1</td><td>3</td><td>Yes</td></tr><tr><td>SCALABILITY_S2T1</td><td>2</td><td>2:1</td><td>1</td><td>No</td></tr><tr><td>SCALABILITY_S2T2</td><td>2</td><td>2:1</td><td>2</td><td>No</td></tr><tr><td>SCALABILITY_S2T3</td><td>2</td><td>2:1</td><td>3</td><td>No</td></tr><tr><td>SCALABILITY_L2T2h</td><td>2</td><td>1.5:1</td><td>2</td><td>Yes</td></tr><tr><td>SCALABILITY_L2T3h</td><td>2</td><td>1.5:1</td><td>3</td><td>Yes</td></tr><tr><td>SCALABILITY_S2T1h</td><td>2</td><td>1.5:1</td><td>1</td><td>No</td></tr></tbody></table>
<p>Table 17. Details in the Temporal and Spatial Mode</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="other-tools">Other Tools<a href="#other-tools" class="hash-link" aria-label="Direct link to Other Tools" title="Direct link to Other Tools">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="quantization-matrices">Quantization Matrices<a href="#quantization-matrices" class="hash-link" aria-label="Direct link to Quantization Matrices" title="Direct link to Quantization Matrices">‚Äã</a></h3>
<p>AV1 support 15 sets of QMs, which are based on the contrast-sensitive functions.
QMs are applied to a frame based on selectable scaling of its quantization
level, higher level of quantization imply flatter matrices. The matrices become
flatter as the quantization index value increases (and the quality decreases).
Inter matrices are slightly flatter than intra matrices.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="superblock-delta-quantization">Superblock Delta-quantization<a href="#superblock-delta-quantization" class="hash-link" aria-label="Direct link to Superblock Delta-quantization" title="Direct link to Superblock Delta-quantization">‚Äã</a></h3>
<p>AV1 allow the per-superblock changes in quantization parameter to support
sub-frame rate control. At the same time it support the ROI level rate control
on the top of segmentation level parameter.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="obu-open-bitstream-unit">OBU (Open Bitstream Unit)<a href="#obu-open-bitstream-unit" class="hash-link" aria-label="Direct link to OBU (Open Bitstream Unit)" title="Direct link to OBU (Open Bitstream Unit)">‚Äã</a></h3>
<p>An AV1 bitstream consists of a number of OBUs that are normally held within a
container format alongside audio and timing information. Here the new tool OBU
is introduced in AV1 and it is similar to NAL (Network Abstract Layer) in
AVC/HEVC spec.</p>
<p>The OBU header is similar to the NAL header. In general the total 8 bits are
presented. The OBU extra 8 bits of extension header is used if temporal and
spatial layer exist in the bitstream. obu_type is the most important syntax to
describe the type of OBU .</p>
<table><thead><tr><th>Index</th><th>obu_type</th></tr></thead><tbody><tr><td>0</td><td>Reserved</td></tr><tr><td>1</td><td>OBU_SEQUENCE_HEADER</td></tr><tr><td>2</td><td>OBU_TD</td></tr><tr><td>3</td><td>OBU_FRAME_HEADER</td></tr><tr><td>4</td><td>OBU_TILE_GROUP</td></tr><tr><td>5</td><td>OBU_METADATA</td></tr><tr><td>6</td><td>OBU_FRAME</td></tr><tr><td>7</td><td>OBU_REDUNDANT_FRAME_HEADER</td></tr><tr><td>8-14</td><td>Reserved</td></tr><tr><td>15</td><td>OBU_PADDING</td></tr></tbody></table>
<p>Table 18. Type of OBU</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References">‚Äã</a></h2>
<ol>
<li><a href="https://aomediacodec.github.io/av1-spec/av1-spec.pdf" target="_blank" rel="noopener noreferrer">https://aomediacodec.github.io/av1-spec/av1-spec.pdf</a></li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/av1-community-contributors/codec-wiki/tree/main/docs/video/AV1.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/video/VP9"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">VP9</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/video/AVS3"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">AVS3</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#abstract" class="table-of-contents__link toc-highlight">Abstract</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#profile--levels" class="table-of-contents__link toc-highlight">Profile &amp; Levels</a></li><li><a href="#block-structure" class="table-of-contents__link toc-highlight">Block Structure</a><ul><li><a href="#basic-coding-block" class="table-of-contents__link toc-highlight">Basic Coding block</a></li><li><a href="#basic-prediction-block" class="table-of-contents__link toc-highlight">Basic Prediction Block</a></li><li><a href="#basic-transform-block" class="table-of-contents__link toc-highlight">Basic Transform Block</a></li></ul></li><li><a href="#intra-prediction" class="table-of-contents__link toc-highlight">Intra Prediction</a><ul><li><a href="#directional-intra-prediction-mode" class="table-of-contents__link toc-highlight">Directional Intra Prediction Mode</a></li><li><a href="#smooth-mode" class="table-of-contents__link toc-highlight">Smooth Mode</a></li><li><a href="#paeth-mode" class="table-of-contents__link toc-highlight">Paeth Mode</a></li><li><a href="#palette-mode" class="table-of-contents__link toc-highlight">Palette Mode</a></li><li><a href="#filter-intra-mode" class="table-of-contents__link toc-highlight">Filter Intra mode</a></li><li><a href="#intra-block-copy-mode" class="table-of-contents__link toc-highlight">Intra Block Copy Mode</a></li><li><a href="#predict-chroma-from-luma" class="table-of-contents__link toc-highlight">Predict Chroma from Luma</a></li></ul></li><li><a href="#inter-prediction" class="table-of-contents__link toc-highlight">Inter Prediction</a><ul><li><a href="#affinewarped-motion-compensation" class="table-of-contents__link toc-highlight">Affine/Warped Motion Compensation</a></li><li><a href="#obmc-overlapped-block-motion-compensation" class="table-of-contents__link toc-highlight">OBMC (Overlapped Block Motion Compensation)</a></li><li><a href="#sub-pixel-interpolation-filter" class="table-of-contents__link toc-highlight">Sub-pixel Interpolation Filter</a></li><li><a href="#dynamic-mv-reference" class="table-of-contents__link toc-highlight">Dynamic MV reference</a></li><li><a href="#extended-compound-modes" class="table-of-contents__link toc-highlight">Extended Compound Modes</a></li><li><a href="#extended-reference-frame-number" class="table-of-contents__link toc-highlight">Extended Reference frame Number</a></li></ul></li><li><a href="#in-loop-filter" class="table-of-contents__link toc-highlight">In-loop Filter</a><ul><li><a href="#de-blocking-filter" class="table-of-contents__link toc-highlight">De-blocking filter</a></li><li><a href="#cdef-constrained-directional-enhancement-filter" class="table-of-contents__link toc-highlight">CDEF (Constrained Directional Enhancement Filter)</a></li><li><a href="#lr-in-loop-restoration-filter" class="table-of-contents__link toc-highlight">LR (In-loop Restoration) filter</a></li></ul></li><li><a href="#multi-symbol-entropy-coder" class="table-of-contents__link toc-highlight">Multi-Symbol Entropy Coder</a></li><li><a href="#transform" class="table-of-contents__link toc-highlight">Transform</a><ul><li><a href="#transform-type" class="table-of-contents__link toc-highlight">Transform type</a></li><li><a href="#transform-block-shape-and-size" class="table-of-contents__link toc-highlight">Transform Block Shape and Size</a></li></ul></li><li><a href="#tiles" class="table-of-contents__link toc-highlight">Tiles</a></li><li><a href="#segment" class="table-of-contents__link toc-highlight">Segment</a></li><li><a href="#svc-scalable-video-coding" class="table-of-contents__link toc-highlight">SVC (Scalable Video Coding)</a></li><li><a href="#other-tools" class="table-of-contents__link toc-highlight">Other Tools</a><ul><li><a href="#quantization-matrices" class="table-of-contents__link toc-highlight">Quantization Matrices</a></li><li><a href="#superblock-delta-quantization" class="table-of-contents__link toc-highlight">Superblock Delta-quantization</a></li><li><a href="#obu-open-bitstream-unit" class="table-of-contents__link toc-highlight">OBU (Open Bitstream Unit)</a></li></ul></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Getting Started</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://wiki.x266.mov/docs/introduction/prologue" target="_blank" rel="noopener noreferrer" class="footer__link-item">Prologue</a></li><li class="footer__item"><a href="https://wiki.x266.mov/docs/audio/AAC" target="_blank" rel="noopener noreferrer" class="footer__link-item">AAC</a></li></ul></div><div class="col footer__col"><div class="footer__title">Filtering</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://wiki.x266.mov/docs/filtering/Vapoursynth" target="_blank" rel="noopener noreferrer" class="footer__link-item">Vapoursynth<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://wiki.x266.mov/docs/filtering/deband" target="_blank" rel="noopener noreferrer" class="footer__link-item">Deband<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://wiki.x266.mov/docs/filtering/denoise" target="_blank" rel="noopener noreferrer" class="footer__link-item">Denoise<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/av1-community-contributors/codec-wiki/tree/main" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contribute<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://wiki.x266.mov/docs/terms-of-use" target="_blank" rel="noopener noreferrer" class="footer__link-item">Terms of Use<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy Policy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2024 Gianni Rosato & contributors. Content licensed under CC BY-SA 4.0. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>