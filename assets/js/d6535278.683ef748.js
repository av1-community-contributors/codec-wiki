"use strict";(self.webpackChunkcodec_wiki=self.webpackChunkcodec_wiki||[]).push([[6977],{4968:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>m,frontMatter:()=>l,metadata:()=>i,toc:()=>h});const i=JSON.parse('{"id":"metrics/VMAF","title":"VMAF","description":"The content in this entry is incomplete & is in the process of being completed.","source":"@site/docs/metrics/VMAF.mdx","sourceDirName":"metrics","slug":"/metrics/VMAF","permalink":"/docs/metrics/VMAF","draft":false,"unlisted":false,"editUrl":"https://github.com/av1-community-contributors/codec-wiki/tree/main/docs/metrics/VMAF.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"VMAF","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"SSIMULACRA2","permalink":"/docs/metrics/SSIMULACRA2"},"next":{"title":"XPSNR","permalink":"/docs/metrics/XPSNR"}}');var s=t(4848),r=t(8453),a=t(5537),o=t(9329);const l={title:"VMAF",sidebar_position:1},c="VMAF",d={},h=[{value:"Installation",id:"installation",level:2},{value:"Using VMAF with FFmpeg",id:"using-vmaf-with-ffmpeg",level:2},{value:"Note about the model path on Windows",id:"note-about-the-model-path-on-windows",level:3},{value:"Scoring",id:"scoring",level:2},{value:"Some weaknesses",id:"some-weaknesses",level:2},{value:"Comparing to SSIMULACRA2",id:"comparing-to-ssimulacra2",level:3}];function u(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"vmaf",children:"VMAF"})}),"\n",(0,s.jsx)(n.admonition,{title:"Under Maintenance",type:"info",children:(0,s.jsx)(n.p,{children:"The content in this entry is incomplete & is in the process of being completed."})}),"\n",(0,s.jsx)(n.p,{children:"Short for Video Multimethod Assessment Fusion, VMAF is a full reference video quality assessment algorithm developed primarily by Netflix."}),"\n",(0,s.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,s.jsxs)(n.p,{children:["Vmaf comes as a part of ",(0,s.jsx)(n.a,{href:"https://github.com/Netflix/vmaf",children:"libvmaf"}),". There are two ways it is commonly used:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["As an ",(0,s.jsx)(n.a,{href:"/docs/utilities/ffmpeg",children:"FFmpeg"})," filter"]}),"\n",(0,s.jsx)(n.li,{children:"As a standalone binary"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The instructions below are written for Linux & macOS. On Windows, you can use the ",(0,s.jsx)(n.a,{href:"https://docs.microsoft.com/en-us/windows/wsl/install",children:"Windows Subsystem for Linux"})," to follow along."]}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsxs)(o.A,{value:"bin",label:"Standalone Binary",children:[(0,s.jsx)(n.p,{children:"In order to build from source, follow the instructions below."}),(0,s.jsxs)(n.ol,{start:"0",children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Install the required dependencies via your package manager of choice. The necessary dependencies are ",(0,s.jsx)(n.code,{children:"nasm"}),", ",(0,s.jsx)(n.code,{children:"ninja-build"}),", ",(0,s.jsx)(n.code,{children:"doxygen"}),", & ",(0,s.jsx)(n.code,{children:"xxd"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Clone the repository & enter the corresponding directory"}),"\n"]}),"\n"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",metastring:'title="Clone & Enter"',children:"git clone https://github.com/Netflix/vmaf/\ncd vmaf/\n"})}),(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsxs)(n.li,{children:["Compile with ",(0,s.jsx)(n.code,{children:"meson"})," & ",(0,s.jsx)(n.code,{children:"ninja"})]}),"\n"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"meson setup libvmaf libvmaf/build --buildtype release -Denable_float=true\nsudo ninja -vC libvmaf/build install\n"})}),(0,s.jsx)(n.p,{children:"Now, you can run the VMAF binary with the following command:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"vmaf --help\n"})}),(0,s.jsxs)(n.p,{children:["If you would not like to build from source, you may grab the latest build from the VMAF ",(0,s.jsx)(n.a,{href:"https://github.com/Netflix/vmaf/releases",children:"GitHub releases"})," for your operating system."]}),(0,s.jsx)(n.p,{children:"Now, you can:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"/path/to/vmaf --reference refrence.y4m --distorted distorted.y4m\n"})}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Tip:"})," If the VMAF binary exists but is not market as executable, you might need to ",(0,s.jsx)(n.code,{children:"chmod +x /path/to/vmaf"})]}),(0,s.jsxs)(n.p,{children:["Explainer on command line flags can be found ",(0,s.jsx)(n.a,{href:"https://github.com/Netflix/vmaf/blob/master/libvmaf/tools/README.md",children:"here"})]}),(0,s.jsx)(n.p,{children:"The disadvantage of using the bin is that you need .yuv|y4m files, you can that overcome by using named pipes\nSimple example using ffmpeg as a decoder:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# create the pipes\nmkfifo ref.pipe\nmkfido dist.pipe\n\n# run these each in a new terminal, order docent matter\nffmpeg -v error -i ref.mkv -strict -1 -f yuv4mpegpipe - > ref.pipe\nffmpeg -v error -i dist.mkv -strict -1 -f yuv4mpegpipe - > dist.pipe\n\n# after starting the two ffmpeg processes,\n# start the vmaf in a new terminal\n/path/to/vmaf --reference ref.pipe --distorted dist.pipe\n\n# delete the pipes after usage\nrm ref.pipe dist.pipe\n"})}),(0,s.jsx)(n.p,{children:"The Advantages of this are:"}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["No need for a ffmpeg build with ",(0,s.jsx)(n.code,{children:"--enable-libvmaf"})]}),"\n",(0,s.jsxs)(n.li,{children:["Clear & simple usage of VMAF's various options, like ",(0,s.jsx)(n.code,{children:"--aom_ctc"})]}),"\n"]}),(0,s.jsx)(n.p,{children:"Disadvantages are:"}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Difficult/awkward to use without a wrapper script"}),"\n"]})]}),(0,s.jsxs)(o.A,{value:"ffmpegfilter",label:"FFmpeg Filter",children:[(0,s.jsxs)(n.p,{children:["If you are not sure if you have VMAF installed, you can check by running ",(0,s.jsx)(n.code,{children:"ffmpeg -help"})," and looking for whether or not the ",(0,s.jsx)(n.code,{children:"--enable-libvmaf"})," flag appears in the banner that is printed to the terminal. If you do not see this, you will need to build ffmpeg from source with the ",(0,s.jsx)(n.code,{children:"--enable-libvmaf"})," flag or grab a pre-compiled build of FFmpeg with the flag enabled."]}),(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.em,{children:["Via the ",(0,s.jsx)(n.a,{href:"https://github.com/Netflix/vmaf/blob/master/resource/doc/ffmpeg.md",children:"VMAF github repo"}),":"]})}),(0,s.jsx)(n.h2,{id:"using-vmaf-with-ffmpeg",children:"Using VMAF with FFmpeg"}),(0,s.jsxs)(n.p,{children:["After installing ",(0,s.jsx)(n.code,{children:"libvmaf"}),", you can use it with ",(0,s.jsx)(n.a,{href:"http://ffmpeg.org/",children:"FFmpeg"}),". Under the FFmpeg directory, configure, build and install FFmpeg with:"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:"./configure --enable-libvmaf\nmake -j4\nmake install\n"})}),(0,s.jsxs)(n.p,{children:["Using FFmpeg+libvmaf is very powerful, as you can create complex filters to calculate VMAF directly on videos of different encoding formats and resolutions. For the best practices of computing VMAF at the right resolution, refer to our ",(0,s.jsx)(n.a,{href:"https://medium.com/netflix-techblog/vmaf-the-journey-continues-44b51ee9ed12",children:"tech blog"}),"."]}),(0,s.jsxs)(n.p,{children:["We provide a few examples how you can construct the FFmpeg command line and use VMAF as a filter. Note that you may need to download the test videos from ",(0,s.jsx)(n.a,{href:"https://github.com/Netflix/vmaf_resource/tree/master/python/test/resource",children:"vmaf_resource"}),"."]}),(0,s.jsxs)(n.p,{children:["Below is an example on how you can run FFmpeg+libvmaf on a pair of YUV files. First, download the reference video ",(0,s.jsx)(n.a,{href:"https://github.com/Netflix/vmaf_resource/blob/master/python/test/resource/yuv/src01_hrc00_576x324.yuv",children:(0,s.jsx)(n.code,{children:"src01_hrc00_576x324.yuv"})})," and the distorted video ",(0,s.jsx)(n.a,{href:"https://github.com/Netflix/vmaf_resource/blob/master/python/test/resource/yuv/src01_hrc01_576x324.yuv",children:(0,s.jsx)(n.code,{children:"src01_hrc01_576x324.yuv"})}),". ",(0,s.jsx)(n.code,{children:"-r 24"})," sets the frame rate (note that it needs to be before ",(0,s.jsx)(n.code,{children:"-i"}),"), and ",(0,s.jsx)(n.code,{children:"PTS-STARTPTS"})," synchronizes the PTS (presentation timestamp) of the two videos (this is crucial if one of your videos does not start at PTS 0, for example, if you cut your video out of a long video stream). It is important to set the frame rate and the PTS right, since FFmpeg filters synchronize based on timestamps instead of frames."]}),(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"log_path"})," is set to standard output ",(0,s.jsx)(n.code,{children:"/dev/stdout"}),". It uses the ",(0,s.jsx)(n.code,{children:"model_path"})," at location ",(0,s.jsx)(n.code,{children:"/usr/local/share/model/vmaf_float_v0.6.1.json"})," (which is the default and can be omitted)."]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:'ffmpeg -video_size 576x324 -r 24 -pixel_format yuv420p -i src01_hrc00_576x324.yuv \\\n    -video_size 576x324 -r 24 -pixel_format yuv420p -i src01_hrc01_576x324.yuv \\\n    -lavfi "[0:v]setpts=PTS-STARTPTS[reference]; \\\n            [1:v]setpts=PTS-STARTPTS[distorted]; \\\n            [distorted][reference]libvmaf=log_fmt=xml:log_path=/dev/stdout:model_path={your_vmaf_dir}/model/vmaf_v0.6.1.json:n_threads=4" \\\n    -f null -\n'})}),(0,s.jsx)(n.p,{children:"The expected output is:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:"[libvmaf @ 0x7fcfa3403980] VMAF score: 76.668905\n"})}),(0,s.jsxs)(n.p,{children:["Below is a more complicated example where the inputs are packaged ",(0,s.jsx)(n.code,{children:".mp4"})," files. It takes in 1) a reference video ",(0,s.jsx)(n.a,{href:"https://github.com/Netflix/vmaf_resource/blob/master/python/test/resource/mp4/Seeking_30_480_1050.mp4",children:(0,s.jsx)(n.code,{children:"Seeking_30_480_1050.mp4"})})," of 480p and 2) a distorted video ",(0,s.jsx)(n.a,{href:"https://github.com/Netflix/vmaf_resource/blob/master/python/test/resource/mp4/Seeking_10_288_375.mp4",children:(0,s.jsx)(n.code,{children:"Seeking_10_288_375.mp4"})})," of 288p upsampled to ",(0,s.jsx)(n.code,{children:"720x480"})," using bicubic, and compute VMAF on the two 480p videos. Bicubic is used as the recommended upsampling method (also see the ",(0,s.jsx)(n.a,{href:"https://medium.com/netflix-techblog/vmaf-the-journey-continues-44b51ee9ed12",children:"techblog"})," for more details)."]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:'ffmpeg \\\n    -r 24 -i Seeking_30_480_1050.mp4 \\\n    -r 24 -i Seeking_10_288_375.mp4 \\\n    -lavfi "[0:v]setpts=PTS-STARTPTS[reference]; \\\n            [1:v]scale=720:480:flags=bicubic,setpts=PTS-STARTPTS[distorted]; \\\n            [distorted][reference]libvmaf=log_fmt=xml:log_path=/dev/stdout:model_path={your_vmaf_dir}/model/vmaf_v0.6.1.json:n_threads=4" \\\n    -f null -\n'})}),(0,s.jsx)(n.p,{children:"The expected output is:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:"[libvmaf @ 0x7fb5b672bc00] VMAF score: 51.017497\n"})}),(0,s.jsxs)(n.p,{children:["See the ",(0,s.jsx)(n.a,{href:"https://ffmpeg.org/ffmpeg-filters.html#libvmaf",children:"FFmpeg's guide to libvmaf"}),", the ",(0,s.jsx)(n.a,{href:"https://trac.ffmpeg.org/wiki/FilteringGuide",children:"FFmpeg Filtering Guide"})," for more examples of complex filters, and the ",(0,s.jsx)(n.a,{href:"https://trac.ffmpeg.org/wiki/Scaling",children:"Scaling Guide"})," for information about scaling and using different scaling algorithms."]}),(0,s.jsx)(n.h3,{id:"note-about-the-model-path-on-windows",children:"Note about the model path on Windows"}),(0,s.jsxs)(n.p,{children:["Due to Windows not having a good default for where to pull the VMAF model from, you will always need to specify ",(0,s.jsx)(n.code,{children:"model_path"})," when calling libvmaf through ",(0,s.jsx)(n.code,{children:"ffmpeg"}),". However, you will need to be careful about the path you pass to ",(0,s.jsx)(n.code,{children:"model_path"}),"."]}),(0,s.jsxs)(n.p,{children:["If you are using a relative path for your ",(0,s.jsx)(n.code,{children:"model_path"}),", you can completely ignore this whole section, else if you are trying to use an absolute Windows path (",(0,s.jsx)(n.code,{children:"D:\\mypath\\vmaf_v0.6.1.json"}),") for your ",(0,s.jsx)(n.code,{children:"model_path"})," argument, you will need to be careful so ",(0,s.jsx)(n.code,{children:"ffmpeg"})," passes the right path to ",(0,s.jsx)(n.code,{children:"libvmaf"}),"."]}),(0,s.jsxs)(n.p,{children:["The final command line will depend on what shell you are running ",(0,s.jsx)(n.code,{children:"ffmpeg"})," through, so you will need to go through the following steps to make sure your path is okay."]}),(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Convert all of the backslashes ",(0,s.jsx)(n.code,{children:"\\"})," to forward slashes ",(0,s.jsx)(n.code,{children:"/"})," (",(0,s.jsx)(n.code,{children:"D:/mypath/vmaf_v0.6.1.json"}),")"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Escape the colon ",(0,s.jsx)(n.code,{children:":"})," character by using a backslash ",(0,s.jsx)(n.code,{children:"\\"})," (",(0,s.jsx)(n.code,{children:"D\\:/mypath/vmaf_v0.6.1.json"}),")"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Then escape that backslash with another backslash (",(0,s.jsx)(n.code,{children:"D\\\\:/mypath/vmaf_v0.6.1.json"}),")"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["The next step will depend on the shell that will run ",(0,s.jsx)(n.code,{children:"ffmpeg"}),":"]}),"\n",(0,s.jsxs)(n.p,{children:["For PowerShell and Command Prompt, this will be enough and your final ",(0,s.jsx)(n.code,{children:"ffmpeg"})," command line will look something like"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:'./ffmpeg.exe -i dist.y4m -i ref.y4m \\\n    -lavfi libvmaf=model_path="D\\\\:/mypath/vmaf_v0.6.1.json" \\\n    -f null -\n'})}),"\n",(0,s.jsx)(n.admonition,{title:"Quoting the path",type:"info",children:(0,s.jsxs)(n.p,{children:["Note: I only quoted the path part for trivial reasons and in this specific case, it can be unquoted or you can quote the whole part after lavfi starting from ",(0,s.jsx)(n.code,{children:"libvmaf"})," to ",(0,s.jsx)(n.code,{children:"json"})," and it should give the same result due to neither shell treating the ",(0,s.jsx)(n.code,{children:"\\"})," as a special character"]})}),"\n",(0,s.jsxs)(n.p,{children:["For bash or specifically msys2 bash, it has some additional considerations. The first thing to know is that bash treats the backslash character ",(0,s.jsx)(n.code,{children:"\\"})," a bit special in that it's an escape character normally when not put inside single quotes. The second thing to know is that msys2's bash attempts convert a posix-like path (",(0,s.jsx)(n.code,{children:"/mingw64/share/model/vmaf_v0.6.1.json"}),") to a Windows mixed path (",(0,s.jsx)(n.code,{children:"D:/msys2/mingw64/share/model/vmaf_v0.6.1.json"}),") when passing arguments to a program. Normally, this would be fine, however, in our case, this works against us since we cannot allow it to convert the path to a normal path with an un-escaped colon. For this, we will need to not only escape the escaped backslash, but we will also need to pass the ",(0,s.jsx)(n.code,{children:"MSYS2_ARG_CONV_EXCL"})," environment variable with the value of ",(0,s.jsx)(n.code,{children:"*"})," to make sure it doesn't apply that special conversion on any of the arguments"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'MSYS2_ARG_CONV_EXCL="*" \\\n    ./ffmpeg.exe -i dist.y4m -i ref.y4m -lavfi \\\n    libvmaf=model_path="D\\\\\\:/mypath/vmaf_v0.6.1.json" -f null -\n'})}),"\n",(0,s.jsx)(n.admonition,{title:"Quotes",type:"info",children:(0,s.jsx)(n.p,{children:"Note: in this case, the quotes are not as trivial as the PowerShell/cmd version, as removing the quotes entirely will require you to re-escape the backslash resulting in 4 total backslashes, but quoting the whole argument will be fine."})}),"\n",(0,s.jsxs)(n.admonition,{title:"Single Quotes",type:"note",children:[(0,s.jsx)(n.p,{children:"Second Note: if you use single quotes around the path, it will be fine as well and the final command line would look like"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"MSYS2_ARG_CONV_EXCL=\"*\" \\\n    ./ffmpeg.exe -i dist.y4m -i ref.y4m -lavfi \\\n    libvmaf=model_path='D\\\\:/mypath/vmaf_v0.6.1.json' -f null -\n"})}),(0,s.jsx)(n.p,{children:"with only a double backslash instead of a triple."})]}),"\n"]}),"\n"]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"scoring",children:"Scoring"}),"\n",(0,s.jsxs)(n.p,{children:["scores range from 0 to 100, and are best interpreted in a linear way,\n100 meaning perfect quality, 0 meaning not recognisable,\nmore info ",(0,s.jsx)(n.a,{href:"https://netflixtechblog.com/vmaf-the-journey-continues-44b51ee9ed12",children:"in the Best Practices section here"}),"\nIt aligns with mean opinion scores (MOS) really well at low/medium bitrates,\nas stated ",(0,s.jsx)(n.a,{href:"https://videoprocessing.ai/benchmarks/video-quality-metrics_both.html",children:"in this benchmark"})]}),"\n",(0,s.jsx)(n.h2,{id:"some-weaknesses",children:"Some weaknesses"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Newer codecs like AV1 and VVC introduce new kinds of artifacting that v0.6.2\n(current model as of Jan 2024) doesn't recognise,\nthat's why its performance might degrade, for example, high motion scenes being affected badly"}),"\n",(0,s.jsx)(n.li,{children:'It\'s bad at "transparent" levels of quality, kinds of quality that the average viewer might not notice'}),"\n",(0,s.jsx)(n.li,{children:"Synthetic grain throws off scores, this issue is not isolated to vmaf, but it should be noted regardless"}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{title:"With ffmpeg you can disable application of synthetic grain",type:"tip",children:(0,s.jsxs)(n.p,{children:["place ",(0,s.jsx)(n.code,{children:"-filmgrain 0"})," before ",(0,s.jsx)(n.code,{children:"-i"})," in the above ffmpeg commands, limited to decoding with dav1d\nTODO: replace this tip with an export_side_data solution"]})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"As of January 2024, it doesn't work on HDR content, nothing prevents you from feeding it un-tonemapped PQ but scores will be off"}),"\n",(0,s.jsx)(n.li,{children:"In contrast with SSIMULACRA2, it focuses on appeal, not necessarily on fidelity. They often align, but not always."}),"\n",(0,s.jsx)(n.li,{children:"Due to the ML nature, comparing the same video to itself will not always result in a score of 100"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"comparing-to-ssimulacra2",children:"Comparing to SSIMULACRA2"}),"\n",(0,s.jsx)(n.p,{children:"One big advantage over SSIMULACRA2 is the inclusion of some temporal information.\nThis means that VMAF weights frames that have a lot of motion higher.\nMeanwhile, SSIMULACRA2 based solutions compare each frame to the reference frame individually, since it is an image\nmetric at heart.\nVMAF also wins in speed and general ease of use."}),"\n",(0,s.jsx)(n.h1,{id:"additional-resources",children:"Additional resources"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/Netflix/vmaf/tree/master/resource/doc",children:"VMAF Documentation on GitHub"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://netflixtechblog.com/vmaf-the-journey-continues-44b51ee9ed12",children:"Medium Article by Netflix"})}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},5537:(e,n,t)=>{t.d(n,{A:()=>w});var i=t(6540),s=t(4164),r=t(5627),a=t(6347),o=t(372),l=t(604),c=t(1861),d=t(8749);function h(e){return i.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:n,children:t}=e;return(0,i.useMemo)((()=>{const e=n??function(e){return h(e).map((({props:{value:e,label:n,attributes:t,default:i}})=>({value:e,label:n,attributes:t,default:i})))}(t);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function m({value:e,tabValues:n}){return n.some((n=>n.value===e))}function f({queryString:e=!1,groupId:n}){const t=(0,a.W6)(),s=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,l.aZ)(s),(0,i.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(t.location.search);n.set(s,e),t.replace({...t.location,search:n.toString()})}),[s,t])]}function p(e){const{defaultValue:n,queryString:t=!1,groupId:s}=e,r=u(e),[a,l]=(0,i.useState)((()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find((e=>e.default))??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:r}))),[c,h]=f({queryString:t,groupId:s}),[p,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,s]=(0,d.Dv)(n);return[t,(0,i.useCallback)((e=>{n&&s.set(e)}),[n,s])]}({groupId:s}),x=(()=>{const e=c??p;return m({value:e,tabValues:r})?e:null})();(0,o.A)((()=>{x&&l(x)}),[x]);return{selectedValue:a,selectValue:(0,i.useCallback)((e=>{if(!m({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);l(e),h(e),g(e)}),[h,g,r]),tabValues:r}}var g=t(9136);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var b=t(4848);function j({className:e,block:n,selectedValue:t,selectValue:i,tabValues:a}){const o=[],{blockElementScrollPositionUntilNextRender:l}=(0,r.a_)(),c=e=>{const n=e.currentTarget,s=o.indexOf(n),r=a[s].value;r!==t&&(l(n),i(r))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=o.indexOf(e.currentTarget)+1;n=o[t]??o[0];break}case"ArrowLeft":{const t=o.indexOf(e.currentTarget)-1;n=o[t]??o[o.length-1];break}}n?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},e),children:a.map((({value:e,label:n,attributes:i})=>(0,b.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{o.push(e)},onKeyDown:d,onClick:c,...i,className:(0,s.A)("tabs__item",x.tabItem,i?.className,{"tabs__item--active":t===e}),children:n??e},e)))})}function v({lazy:e,children:n,selectedValue:t}){const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=r.find((e=>e.props.value===t));return e?(0,i.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:r.map(((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==t})))})}function y(e){const n=p(e);return(0,b.jsxs)("div",{className:(0,s.A)("tabs-container",x.tabList),children:[(0,b.jsx)(j,{...n,...e}),(0,b.jsx)(v,{...n,...e})]})}function w(e){const n=(0,g.A)();return(0,b.jsx)(y,{...e,children:h(e.children)},String(n))}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(6540);const s={},r=i.createContext(s);function a(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:n},e.children)}},9329:(e,n,t)=>{t.d(n,{A:()=>a});t(6540);var i=t(4164);const s={tabItem:"tabItem_Ymn6"};var r=t(4848);function a({children:e,hidden:n,className:t}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,i.A)(s.tabItem,t),hidden:n,children:e})}}}]);