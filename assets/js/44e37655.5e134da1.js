"use strict";(self.webpackChunkcodec_wiki=self.webpackChunkcodec_wiki||[]).push([[5958],{3453:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>o,contentTitle:()=>l,default:()=>u,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"metrics/SSIMULACRA2","title":"SSIMULACRA2","description":"SSIMULACRA2 is a visual fidelity metric based on the concept of the multi-scale structural similarity index measure (MS-SSIM), computed in a perceptually relevant color space, adding two other (asymmetric) error maps, and aggregating using two different norms. It is currently the most reputable visual quality metric according to its correlation with subjective results, and is considered a very robust means of comparing encoders. It is debatable whether Butteraugli is better for very high fidelity, but SSIMULACRA2 is considered the best for medium/low fidelity comparisons.","source":"@site/docs/metrics/SSIMULACRA2.mdx","sourceDirName":"metrics","slug":"/metrics/SSIMULACRA2","permalink":"/docs/metrics/SSIMULACRA2","draft":false,"unlisted":false,"editUrl":"https://github.com/av1-community-contributors/codec-wiki/tree/main/docs/metrics/SSIMULACRA2.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"SSIMULACRA2","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"SSIM","permalink":"/docs/metrics/SSIM"},"next":{"title":"VMAF","permalink":"/docs/metrics/VMAF"}}');var r=i(4848),n=i(8453);i(7244),i(6778);const s={title:"SSIMULACRA2",sidebar_position:1},l="SSIMULACRA2",o={},c=[{value:"Scoring",id:"scoring",level:2},{value:"Metric Breakdown",id:"metric-breakdown",level:2},{value:"Convert sRGB to Linear RGB",id:"convert-srgb-to-linear-rgb",level:3},{value:"Transform to XYB",id:"transform-to-xyb",level:3},{value:"Normalize Values",id:"normalize-values",level:3},{value:"Build a Multi-Scale Image Pyramid",id:"build-a-multi-scale-image-pyramid",level:3},{value:"Blurred Statistics",id:"blurred-statistics",level:3},{value:"Similarity &amp; Artifacts",id:"similarity--artifacts",level:3},{value:"Aggregate statistics per channel and scale",id:"aggregate-statistics-per-channel-and-scale",level:3},{value:"Weighted combination of statistics",id:"weighted-combination-of-statistics",level:3},{value:"Nonlinear mapping to final score",id:"nonlinear-mapping-to-final-score",level:3},{value:"Notes",id:"notes",level:2},{value:"Implementations",id:"implementations",level:2},{value:"Cloudinary&#39;s SSIMULACRA2",id:"cloudinarys-ssimulacra2",level:3},{value:"<code>vapoursynth-zip</code> Filter",id:"vapoursynth-zip-filter",level:3},{value:"fssimu2",id:"fssimu2",level:3},{value:"vship",id:"vship",level:3},{value:"<code>ssimulacra2_rs</code>",id:"ssimulacra2_rs",level:3}];function d(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,n.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"ssimulacra2",children:"SSIMULACRA2"})}),"\n",(0,r.jsxs)(t.p,{children:["SSIMULACRA2 is a visual fidelity metric based on the concept of the multi-scale structural similarity index measure (MS-SSIM), computed in a perceptually relevant color space, adding two other (asymmetric) error maps, and aggregating using two different norms. It is currently the most reputable visual quality metric according to its correlation with subjective results, and is considered a very robust means of comparing encoders. It is debatable whether ",(0,r.jsx)(t.a,{href:"/docs/metrics/butteraugli",children:"Butteraugli"})," is better for very high fidelity, but SSIMULACRA2 is considered the best for medium/low fidelity comparisons."]}),"\n",(0,r.jsx)(t.h2,{id:"scoring",children:"Scoring"}),"\n",(0,r.jsx)(t.p,{children:"The score that SSIMULACRA 2 outputs is simple: a number in range -inf..100. According to the developers of the metric, for image quality assessment, SSIMULACRA 2 scores correlate to subjective visual quality as follows:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["Very high quality: ",(0,r.jsx)(t.code,{children:"90"})," and above"]}),"\n",(0,r.jsxs)(t.li,{children:["High quality: ",(0,r.jsx)(t.code,{children:"70"})," to ",(0,r.jsx)(t.code,{children:"90"})]}),"\n",(0,r.jsxs)(t.li,{children:["Medium quality: ",(0,r.jsx)(t.code,{children:"50"})," to ",(0,r.jsx)(t.code,{children:"70"})]}),"\n",(0,r.jsxs)(t.li,{children:["Low quality: Below ",(0,r.jsx)(t.code,{children:"50"})]}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"metric-breakdown",children:"Metric Breakdown"}),"\n",(0,r.jsx)(t.p,{children:"A step-by-step description of the SSIMULACRA2 metric follows. The steps assume we have two input images, a reference image as well as a distorted image to be compared and scored."}),"\n",(0,r.jsx)(t.h3,{id:"convert-srgb-to-linear-rgb",children:"Convert sRGB to Linear RGB"}),"\n",(0,r.jsx)(t.p,{children:"Undo the sRGB gamma curve to obtain linear light values for each RGB channel.\nThis converts perceptual-encoded pixel values into physically meaningful intensities."}),"\n",(0,r.jsx)(t.h3,{id:"transform-to-xyb",children:"Transform to XYB"}),"\n",(0,r.jsx)(t.p,{children:"Map linear RGB into an opsin-inspired space that separates perceptual channels.\nSteps: apply an absorbance-like linear transform, clamp negatives, take a cube root to compress dynamic range, add small biases, then mix into three channels (X, Y, B).\nResulting channels are tuned to align better with human vision than raw RGB."}),"\n",(0,r.jsx)(t.h3,{id:"normalize-values",children:"Normalize Values"}),"\n",(0,r.jsx)(t.p,{children:"Apply slight shifts and scalings so all channel values are positive and stable for later statistical operations.\nThis prevents division instability and extreme ratios in subsequent steps."}),"\n",(0,r.jsx)(t.h3,{id:"build-a-multi-scale-image-pyramid",children:"Build a Multi-Scale Image Pyramid"}),"\n",(0,r.jsx)(t.p,{children:"Create multiple downscaled versions of both images (typically several scales, each half the previous dimension).\nEach scale captures structure at a different spatial frequency.\nThe metric computes statistics independently at every scale."}),"\n",(0,r.jsx)(t.h3,{id:"blurred-statistics",children:"Blurred Statistics"}),"\n",(0,r.jsx)(t.p,{children:"For each scale and each perceptual channel, compute local blurred statistics. Local blurred quantities are computed on each pixel using a separable spatial blur:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Local mean (blurred image)."}),"\n",(0,r.jsx)(t.li,{children:"Local second moments: blurred squared values and blurred cross-products between reference and distorted channels."}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"These give local variance and covariance estimates analogous to SSIM\u2019s variance/covariance."}),"\n",(0,r.jsx)(t.h3,{id:"similarity--artifacts",children:"Similarity & Artifacts"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Similarity map (SSIM-like):"}),"\nCombine local means, variances, and covariance into a per-pixel similarity value.\nThis value measures structural agreement while using small stabilizing constants to avoid division by zero.\nSimilarity is clamped to a sensible range and emphasizes structural fidelity."]}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Edge / artifact map:"}),"\nCompare local deviations from local means between distorted and reference images to detect:"]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"New artifacts (excess local detail or harsh edges introduced by distortion)."}),"\n",(0,r.jsx)(t.li,{children:"Lost detail (original detail suppressed or blurred).\nCompute per-pixel artifact and lost-detail measures, and preserve higher-order statistics to capture outliers."}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"aggregate-statistics-per-channel-and-scale",children:"Aggregate statistics per channel and scale"}),"\n",(0,r.jsx)(t.p,{children:"Across each channel and scale compute compact summaries:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Mean of the per-pixel similarity and artifact/lost-detail measures."}),"\n",(0,r.jsx)(t.li,{children:"Higher-order moment summaries (fourth-moment based measures reduced by a fourth-root) to detect heavy tails and strong local errors."}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"These condensed statistics encode both average behavior and extreme localized errors."}),"\n",(0,r.jsx)(t.h3,{id:"weighted-combination-of-statistics",children:"Weighted combination of statistics"}),"\n",(0,r.jsx)(t.p,{children:"Multiply each aggregated statistic by a pre-tuned weight.\nSum all weighted terms across channels and scales to produce a single scalar accumulator.\nWeights are learned/tuned to map the diverse statistics into a perceptually meaningful predictor."}),"\n",(0,r.jsx)(t.h3,{id:"nonlinear-mapping-to-final-score",children:"Nonlinear mapping to final score"}),"\n",(0,r.jsx)(t.p,{children:"Pass the accumulator through a nonlinear curve (polynomial and a power-law transform).\nThis mapping compresses the predictor into a bounded perceptual score.\nThe final value is expressed on a convenient scale where higher means better and values near the top indicate imperceptible differences."}),"\n",(0,r.jsx)(t.h2,{id:"notes",children:"Notes"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"The metric examines structure and edge behavior separately. It penalizes both new artifacts and lost detail."}),"\n",(0,r.jsx)(t.li,{children:"Multi-scale analysis makes it sensitive to distortions at different spatial frequencies."}),"\n",(0,r.jsx)(t.li,{children:"Aggregating higher-order moments preserves sensitivity to rare but visually important outliers."}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"implementations",children:"Implementations"}),"\n",(0,r.jsx)(t.p,{children:"There are a couple of different SSIMULACRA2 implementations available, some useful in different contexts."}),"\n",(0,r.jsx)(t.h3,{id:"cloudinarys-ssimulacra2",children:"Cloudinary's SSIMULACRA2"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"https://github.com/cloudinary/ssimulacra2",children:"Cloudinary's SSIMULACRA2 implementation"})," is the reference implementation written in C++. It comes from the libjxl project, the reference implementation of the ",(0,r.jsx)(t.a,{href:"/docs/images/JXL",children:"JPEG XL"})," image codec."]}),"\n",(0,r.jsxs)(t.h3,{id:"vapoursynth-zip-filter",children:[(0,r.jsx)(t.code,{children:"vapoursynth-zip"})," Filter"]}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"https://github.com/dnjulek/vapoursynth-zip",children:(0,r.jsx)(t.code,{children:"vapoursynth-zip"})})," is a collection of filters for use with ",(0,r.jsx)(t.a,{href:"/docs/filtering/vapoursynth",children:"Vapoursynth"}),". It is written in Zig, and features a SSIMULACRA2 implementation."]}),"\n",(0,r.jsx)(t.h3,{id:"fssimu2",children:"fssimu2"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"https://github.com/gianni-rosato/fssimu2",children:"fssimu2"})," is a fast SSIMULACRA2 implementation written in Zig. It is designed for speed, claiming to be up to 14% more performant while using just 50% of the memory. It displays a recorded error of ~1.5% relative to Cloudinary's reference implementation, and it achieves 99.7% correlation according to the Pearson correlation coefficient documented in the README. It is based on Julek's Zig implementation."]}),"\n",(0,r.jsx)(t.h3,{id:"vship",children:"vship"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"https://github.com/Line-fr/Vship",children:"Vship"})," is a GPU-accelerated metrics toolkit compatible with Vapoursynth. It also features its own standalone FFVship binary, available independent of Vapoursynth. Vship's SSIMULACRA2 implementation is an order of magnitude faster than CPU-based implementations, and has reportedly high correlation with the reference implementation."]}),"\n",(0,r.jsx)(t.h3,{id:"ssimulacra2_rs",children:(0,r.jsx)(t.code,{children:"ssimulacra2_rs"})}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"https://github.com/rust-av/ssimulacra2_bin",children:(0,r.jsx)(t.code,{children:"ssimulacra2_rs"})})," is a binary interface to the ",(0,r.jsx)(t.a,{href:"https://github.com/rust-av/ssimulacra2",children:"Rust implementation of the SSIMULACRA2 metric"}),". It is notable for being one of the first independent implementations, as well as one of the first to consider video inputs."]})]})}function u(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},6778:(e,t,i)=>{i.d(t,{A:()=>s});i(6540);var a=i(4164);const r={tabItem:"tabItem_Ymn6"};var n=i(4848);function s(e){let{children:t,hidden:i,className:s}=e;return(0,n.jsx)("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,s),hidden:i,children:t})}},7244:(e,t,i)=>{i.d(t,{A:()=>A});var a=i(6540),r=i(4164),n=i(9872),s=i(4319),l=i(6347),o=i(4280),c=i(3024),d=i(8417),u=i(4031);function h(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function m(e){const{values:t,children:i}=e;return(0,a.useMemo)((()=>{const e=t??function(e){return h(e).map((e=>{let{props:{value:t,label:i,attributes:a,default:r}}=e;return{value:t,label:i,attributes:a,default:r}}))}(i);return function(e){const t=(0,d.XI)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,i])}function p(e){let{value:t,tabValues:i}=e;return i.some((e=>e.value===t))}function f(e){let{queryString:t=!1,groupId:i}=e;const r=(0,l.W6)(),n=function(e){let{queryString:t=!1,groupId:i}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!i)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return i??null}({queryString:t,groupId:i});return[(0,c.aZ)(n),(0,a.useCallback)((e=>{if(!n)return;const t=new URLSearchParams(r.location.search);t.set(n,e),r.replace({...r.location,search:t.toString()})}),[n,r])]}function v(e){const{defaultValue:t,queryString:i=!1,groupId:r}=e,n=m(e),[s,l]=(0,a.useState)((()=>function(e){let{defaultValue:t,tabValues:i}=e;if(0===i.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!p({value:t,tabValues:i}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${i.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=i.find((e=>e.default))??i[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:n}))),[c,d]=f({queryString:i,groupId:r}),[h,v]=function(e){let{groupId:t}=e;const i=function(e){return e?`docusaurus.tab.${e}`:null}(t),[r,n]=(0,u.Dv)(i);return[r,(0,a.useCallback)((e=>{i&&n.set(e)}),[i,n])]}({groupId:r}),b=(()=>{const e=c??h;return p({value:e,tabValues:n})?e:null})();(0,o.A)((()=>{b&&l(b)}),[b]);return{selectedValue:s,selectValue:(0,a.useCallback)((e=>{if(!p({value:e,tabValues:n}))throw new Error(`Can't select invalid tab value=${e}`);l(e),d(e),v(e)}),[d,v,n]),tabValues:n}}var b=i(6916);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=i(4848);function y(e){let{className:t,block:i,selectedValue:a,selectValue:n,tabValues:l}=e;const o=[],{blockElementScrollPositionUntilNextRender:c}=(0,s.a_)(),d=e=>{const t=e.currentTarget,i=o.indexOf(t),r=l[i].value;r!==a&&(c(t),n(r))},u=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const i=o.indexOf(e.currentTarget)+1;t=o[i]??o[0];break}case"ArrowLeft":{const i=o.indexOf(e.currentTarget)-1;t=o[i]??o[o.length-1];break}}t?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":i},t),children:l.map((e=>{let{value:t,label:i,attributes:n}=e;return(0,x.jsx)("li",{role:"tab",tabIndex:a===t?0:-1,"aria-selected":a===t,ref:e=>{o.push(e)},onKeyDown:u,onClick:d,...n,className:(0,r.A)("tabs__item",g.tabItem,n?.className,{"tabs__item--active":a===t}),children:i??t},t)}))})}function j(e){let{lazy:t,children:i,selectedValue:n}=e;const s=(Array.isArray(i)?i:[i]).filter(Boolean);if(t){const e=s.find((e=>e.props.value===n));return e?(0,a.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:s.map(((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==n})))})}function S(e){const t=v(e);return(0,x.jsxs)("div",{className:(0,r.A)(n.G.tabs.container,"tabs-container",g.tabList),children:[(0,x.jsx)(y,{...t,...e}),(0,x.jsx)(j,{...t,...e})]})}function A(e){const t=(0,b.A)();return(0,x.jsx)(S,{...e,children:h(e.children)},String(t))}},8453:(e,t,i)=>{i.d(t,{R:()=>s,x:()=>l});var a=i(6540);const r={},n=a.createContext(r);function s(e){const t=a.useContext(n);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),a.createElement(n.Provider,{value:t},e.children)}}}]);