"use strict";(self.webpackChunkcodec_wiki=self.webpackChunkcodec_wiki||[]).push([[5885],{7803:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"filtering/stabilizing","title":"Stabilizing","description":"This section is in need of contributions. If you believe you can help, please see our Contribution Guide to get started as a contributor!","source":"@site/docs/filtering/stabilizing.mdx","sourceDirName":"filtering","slug":"/filtering/stabilizing","permalink":"/docs/filtering/stabilizing","draft":false,"unlisted":false,"editUrl":"https://github.com/av1-community-contributors/codec-wiki/tree/main/docs/filtering/stabilizing.mdx","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"title":"Stabilizing","sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Decombing","permalink":"/docs/filtering/decombing"},"next":{"title":"Denoise","permalink":"/docs/filtering/denoise"}}');var n=t(4848),r=t(8453);const o={title:"Stabilizing",sidebar_position:7},a="Stabilizing",l={},d=[{value:"Overview",id:"overview",level:2},{value:"Usage",id:"usage",level:2},{value:"vidstabdetect Parameters",id:"vidstabdetect-parameters",level:3},{value:"vidstabtransform Parameters",id:"vidstabtransform-parameters",level:3},{value:"Notes",id:"notes",level:2}];function c(e){const i={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i.header,{children:(0,n.jsx)(i.h1,{id:"stabilizing",children:"Stabilizing"})}),"\n",(0,n.jsx)(i.admonition,{title:"Help Wanted",type:"danger",children:(0,n.jsxs)(i.p,{children:["This section is in need of contributions. If you believe you can help, please see our ",(0,n.jsx)(i.a,{href:"/docs/contribution-guide",children:"Contribution Guide"})," to get started as a contributor!"]})}),"\n",(0,n.jsx)(i.h2,{id:"overview",children:"Overview"}),"\n",(0,n.jsxs)(i.p,{children:["Stabilizing is the process of reducing unwanted camera movement and shakes in video clips using ",(0,n.jsx)(i.a,{href:"/docs/utilities/ffmpeg",children:"FFmpeg"}),". This improves overall encoding efficiency by minimizing unpredictable global movement, such as that from handheld cameras. The recommended method for stabilizing videos with FFmpeg is to use the VidStab library, which requires a build of FFmpeg compiled with ",(0,n.jsx)(i.code,{children:"--enable-libvidstab"}),"."]}),"\n",(0,n.jsx)(i.p,{children:"VidStab offers two filters within FFmpeg:"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-shell",children:"ffmpeg -hide_banner -filters | grep vidstab\n ... vidstabdetect     V->V       Extract relative transformations, pass 1 of 2 for stabilization (see vidstabtransform for pass 2).\n ... vidstabtransform  V->V       Transform the frames, pass 2 of 2 for stabilization (see vidstabdetect for pass 1).\n"})}),"\n",(0,n.jsxs)(i.p,{children:["The ",(0,n.jsx)(i.code,{children:"vidstabdetect"})," filter is used in the first pass to generate a video transformations file (",(0,n.jsx)(i.code,{children:".trf"}),"), while ",(0,n.jsx)(i.code,{children:"vidstabtransform"})," is employed in the second pass to apply those transformations."]}),"\n",(0,n.jsx)(i.h2,{id:"usage",children:"Usage"}),"\n",(0,n.jsx)(i.p,{children:"To stabilize a video using default parameters, follow these two steps:"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-shell",children:"ffmpeg -i input.mp4 -vf vidstabdetect -f null -\nffmpeg -i input.mp4 -vf vidstabtransform output.mp4\n"})}),"\n",(0,n.jsxs)(i.p,{children:["After running the first command, a ",(0,n.jsx)(i.code,{children:"transforms.trf"})," file will be created in the directory where you executed FFmpeg. Once the stabilization process is complete, you can safely delete this file. The resulting ",(0,n.jsx)(i.code,{children:"output.mp4"})," video will have reduced shakiness."]}),"\n",(0,n.jsx)(i.p,{children:"For stabilizing high-framerate videos with strong camera movement:"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-shell",children:"ffmpeg -i input.mp4 -vf vidstabdetect=shakiness=8:result=a.trf -f null -\nffmpeg -i input.mp4 -vf vidstabtransform=smoothing=30:zoom=-5:input=a.trf output.mp4\n"})}),"\n",(0,n.jsx)(i.admonition,{type:"tip",children:(0,n.jsxs)(i.p,{children:["Remember to set appropriate video/audio codec parameters in the command before ",(0,n.jsx)(i.code,{children:"output.mp4"}),". You must not use ",(0,n.jsx)(i.code,{children:"-c:v copy"}),", as the video will undergo transformations."]})}),"\n",(0,n.jsx)(i.h3,{id:"vidstabdetect-parameters",children:"vidstabdetect Parameters"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"result"})," - Sets the output ",(0,n.jsx)(i.code,{children:".trf"})," file location"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"shakiness"})," - Adjusts movement reduction, with ",(0,n.jsx)(i.code,{children:"1"})," being the least and ",(0,n.jsx)(i.code,{children:"10"})," the most reduction (highest stabilization). Default is ",(0,n.jsx)(i.code,{children:"5"}),"."]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"accuracy"})," - Controls movement reduction accuracy. Lower values use less CPU but may be less accurate. FFmpeg's minimum allowed value is ",(0,n.jsx)(i.code,{children:"3"}),". Processing speed was approximately ",(0,n.jsx)(i.code,{children:"21 fps"})," at ",(0,n.jsx)(i.code,{children:"3"})," and ",(0,n.jsx)(i.code,{children:"14 fps"})," at ",(0,n.jsx)(i.code,{children:"15"}),"."]}),"\n"]}),"\n",(0,n.jsxs)(i.p,{children:["For a complete list of parameters, refer to the ",(0,n.jsx)(i.a,{href:"https://ffmpeg.org/ffmpeg-filters.html#vidstabdetect-1",children:"vidstabdetect documentation"}),"."]}),"\n",(0,n.jsx)(i.h3,{id:"vidstabtransform-parameters",children:"vidstabtransform Parameters"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"input"})," - Specifies the input ",(0,n.jsx)(i.code,{children:".trf"})," file created by ",(0,n.jsx)(i.code,{children:"vidstabdetect"})]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"smoothing"})," - Determines the number of frames considered for future and past movement estimation. Default is ",(0,n.jsx)(i.code,{children:"10"}),"."]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"zoom"})," - Adjusts the zoom percentage, with ",(0,n.jsx)(i.code,{children:"0%"})," being the default. Negative values create a zoom-out effect."]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"interpol"})," - Sets the type of interpolation used:","\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"no"})," - No interpolation"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"linear"})," - Only horizontal"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"bilinear"})," - Faster but may result in blurry output (default)"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"bicubic"})," - Slower"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(i.p,{children:["See the ",(0,n.jsx)(i.a,{href:"https://ffmpeg.org/ffmpeg-filters.html#vidstabtransform-1",children:"vidstabtransform documentation"})," for more details."]}),"\n",(0,n.jsx)(i.h2,{id:"notes",children:"Notes"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:"Stabilization is a lossy process that can reduce video quality due to zoom and interpolation effects."}),"\n",(0,n.jsx)(i.li,{children:"Some users may notice overall wobbliness in stabilized videos, especially at higher stabilization levels. This is an inherent characteristic of this filter."}),"\n",(0,n.jsx)(i.li,{children:"Depending on your use case, consider employing two-pass encoding along with these stabilization steps."}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,n.jsx)(i,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},8453:(e,i,t)=>{t.d(i,{R:()=>o,x:()=>a});var s=t(6540);const n={},r=s.createContext(n);function o(e){const i=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),s.createElement(r.Provider,{value:i},e.children)}}}]);