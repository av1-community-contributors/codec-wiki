"use strict";(self.webpackChunkcodec_wiki=self.webpackChunkcodec_wiki||[]).push([[2897],{2458:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>a,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"video/AV1","title":"AV1","description":"AV1 is a royalty-free video compression format designed to succeed VP9. It presently competes with VP9, VVC, and HEVC. AV1 is computationally more complex than VP9, but is fast to decode due to the mature and efficient dav1d AV1 decoder. AV1 hardware accelerated decoding is also available on a variety of different consumer hardware devices, all of which are enumerated on Wikipedia. Standout entries include modern Intel, AMD, & Nvidia integrated & discrete GPUs, Google\'s Tensor SoC powering the Pixel line, Apple\'s A17 Pro in the iPhone 15 Pro series, and modern Mediatek & Qualcomm chips. YouTube is currently in the process of transitioning their videos to use AV1.","source":"@site/docs/video/AV1.mdx","sourceDirName":"video","slug":"/video/AV1","permalink":"/docs/video/AV1","draft":false,"unlisted":false,"editUrl":"https://github.com/av1-community-contributors/codec-wiki/tree/main/docs/video/AV1.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"title":"AV1","sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"VP9","permalink":"/docs/video/VP9"},"next":{"title":"AVS3","permalink":"/docs/video/AVS3"}}');var r=i(4848),d=i(8453);const s={title:"AV1",sidebar_position:6},l="AV1",o={},c=[{value:"Abstract",id:"abstract",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Profile &amp; Levels",id:"profile--levels",level:2},{value:"Block Structure",id:"block-structure",level:2},{value:"Basic Coding block",id:"basic-coding-block",level:3},{value:"Basic Prediction Block",id:"basic-prediction-block",level:3},{value:"Basic Transform Block",id:"basic-transform-block",level:3},{value:"Intra Prediction",id:"intra-prediction",level:2},{value:"Directional Intra Prediction Mode",id:"directional-intra-prediction-mode",level:3},{value:"Smooth Mode",id:"smooth-mode",level:3},{value:"Paeth Mode",id:"paeth-mode",level:3},{value:"Palette Mode",id:"palette-mode",level:3},{value:"Filter Intra mode",id:"filter-intra-mode",level:3},{value:"Intra Block Copy Mode",id:"intra-block-copy-mode",level:3},{value:"Predict Chroma from Luma",id:"predict-chroma-from-luma",level:3},{value:"Inter Prediction",id:"inter-prediction",level:2},{value:"Affine/Warped Motion Compensation",id:"affinewarped-motion-compensation",level:3},{value:"OBMC (Overlapped Block Motion Compensation)",id:"obmc-overlapped-block-motion-compensation",level:3},{value:"Sub-pixel Interpolation Filter",id:"sub-pixel-interpolation-filter",level:3},{value:"Dynamic MV reference",id:"dynamic-mv-reference",level:3},{value:"Extended Compound Modes",id:"extended-compound-modes",level:3},{value:"Extended Reference frame Number",id:"extended-reference-frame-number",level:3},{value:"In-loop Filter",id:"in-loop-filter",level:2},{value:"De-blocking filter",id:"de-blocking-filter",level:3},{value:"CDEF (Constrained Directional Enhancement Filter)",id:"cdef-constrained-directional-enhancement-filter",level:3},{value:"LR (In-loop Restoration) filter",id:"lr-in-loop-restoration-filter",level:3},{value:"Multi-Symbol Entropy Coder",id:"multi-symbol-entropy-coder",level:2},{value:"Transform",id:"transform",level:2},{value:"Transform type",id:"transform-type",level:3},{value:"Transform Block Shape and Size",id:"transform-block-shape-and-size",level:3},{value:"Tiles",id:"tiles",level:2},{value:"Segment",id:"segment",level:2},{value:"SVC (Scalable Video Coding)",id:"svc-scalable-video-coding",level:2},{value:"Other Tools",id:"other-tools",level:2},{value:"Quantization Matrices",id:"quantization-matrices",level:3},{value:"Superblock Delta-quantization",id:"superblock-delta-quantization",level:3},{value:"OBU (Open Bitstream Unit)",id:"obu-open-bitstream-unit",level:3},{value:"References",id:"references",level:2}];function h(e){const n={a:"a",blockquote:"blockquote",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,d.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"av1",children:"AV1"})}),"\n",(0,r.jsxs)(n.p,{children:["AV1 is a royalty-free video compression format designed to succeed ",(0,r.jsx)(n.a,{href:"/docs/video/VP9",children:"VP9"}),". It presently competes with ",(0,r.jsx)(n.a,{href:"/docs/video/VP9",children:"VP9"}),", ",(0,r.jsx)(n.a,{href:"/docs/video/VVC",children:"VVC"}),", and ",(0,r.jsx)(n.a,{href:"/docs/video/HEVC",children:"HEVC"}),". AV1 is computationally more complex than VP9, but is fast to decode due to the mature and efficient dav1d AV1 decoder. AV1 hardware accelerated decoding is also available on a variety of different consumer hardware devices, all of which are enumerated ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/AV1#Hardware",children:"on Wikipedia"}),". Standout entries include modern Intel, AMD, & Nvidia integrated & discrete GPUs, Google's Tensor SoC powering the Pixel line, Apple's A17 Pro in the iPhone 15 Pro series, and modern Mediatek & Qualcomm chips. YouTube is currently in the process of transitioning their videos to use AV1."]}),"\n",(0,r.jsxs)(n.p,{children:["There are a number of viable AV1 encoding solutions available today. The three best, most ubiquitous, and free implementations are ",(0,r.jsx)(n.a,{href:"/docs/encoders/aomenc",children:"aomenc"}),", ",(0,r.jsx)(n.a,{href:"/docs/encoders/SVT-AV1",children:"SVT-AV1"}),", & ",(0,r.jsx)(n.a,{href:"/docs/encoders/rav1e",children:"rav1e"}),"."]}),"\n",(0,r.jsx)(n.h1,{id:"a-technical-overview-of-av1",children:"A Technical Overview of AV1"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.em,{children:["This section has been graciously borrowed from Qu Pengfei's amazing ",(0,r.jsx)(n.a,{href:"https://github.com/QuPengfei/Technical-Overview-Of-AV1-Spec/blob/master/README.md",children:"AV1 README.md"}),", with some minor grammar, formatting, and spelling corrections. Thank you, Qu Pengfei!"]})}),"\n",(0,r.jsx)(n.h2,{id:"abstract",children:"Abstract"}),"\n",(0,r.jsx)(n.p,{children:"AV1 (AOMedia Video Codec 1.0) evolved on the basis of VP9 (Google), Thor (Cisco)\nand Daala (Mozila) under the AOM (Alliance for Open Media). It includes a number\nof enhancement and the new tools that have been added to improve the coding\nefficiency. The new tools that are added so far include 4 main aspects:\nprediction, transform, in-loop filter and entropy encoder. This document\nprovides a snapshot of the coding tools in the current finalized version (on\nMarch, 2018) of AV1 spec."}),"\n",(0,r.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:"According to the AOM web page, AV1 is designed with the following feature."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Royally free"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Scales to any modern device at any bandwidth"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"For use in both commercial and non-commercial content, including\nuser-generated content"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Developed for the internet and related applications and services-from\nbrowsers and streaming to videoconferencing services"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Designed with a low computational footprint and optimized for hardware"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Bringing features like 4k UHD, HDR, and WCG to real-time video"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"profile--levels",children:"Profile & Levels"}),"\n",(0,r.jsx)(n.p,{children:"Profiles and levels specify restrictions on the capabilities needed to decode\nthe bitstreams. The profile specifies the bit depth and subsampling formats\nsupported, while the level defines resolution and performance characteristics.\nBy now levels is still under discussion and there is no more details."}),"\n",(0,r.jsx)(n.p,{children:"AV1 support the three named profiles as the table list."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Profile"}),(0,r.jsx)(n.th,{children:"Bit depth"}),(0,r.jsx)(n.th,{children:"Monochrome support"}),(0,r.jsx)(n.th,{children:"Chroma subsampling"}),(0,r.jsx)(n.th,{children:"Name"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"8/10"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"4:2:0"}),(0,r.jsx)(n.td,{children:"Main"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"8/10"}),(0,r.jsx)(n.td,{children:"No"}),(0,r.jsx)(n.td,{children:"4:4:4"}),(0,r.jsx)(n.td,{children:"High"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"8/10"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"4:2:2"}),(0,r.jsx)(n.td,{children:"Professional"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"12"}),(0,r.jsx)(n.td,{children:"Yes"}),(0,r.jsx)(n.td,{children:"4:2:0, 4:2:2, 4:4:4"}),(0,r.jsx)(n.td,{children:"Professional"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 1. AV1 Profile"}),"\n",(0,r.jsx)(n.h2,{id:"block-structure",children:"Block Structure"}),"\n",(0,r.jsx)(n.h3,{id:"basic-coding-block",children:"Basic Coding block"}),"\n",(0,r.jsx)(n.p,{children:"AV1 support the larger super block size, which is up to 128x128 super block is\nallowed. It supports from 128x128 down to 4x4 coding block. Each 4x4 luma block\nis allowed to independently select inter or intra mode, its reference mode, and\ninterpolation filter type. For Chroma, 2x2 block size is allowed but still 4x4\ntransform block size is used."}),"\n",(0,r.jsx)(n.h3,{id:"basic-prediction-block",children:"Basic Prediction Block"}),"\n",(0,r.jsx)(n.p,{children:"AV1 support up to 10 partition type. The size of partition unit is allowed down\nto 4x4 and totally there are 24 types of block size."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Partition index"}),(0,r.jsx)(n.th,{children:"Type of partition"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"PARTITION_NONE"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"PARTITION_HORZ"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"PARTITION_VERT"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"PARTITION_SPLIT"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"PARTITION_HORZ_A"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"PARTITION_HORZ_B"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6"}),(0,r.jsx)(n.td,{children:"PARTITION_VERT_A"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"PARTITION_VERT_B"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"8"}),(0,r.jsx)(n.td,{children:"PARTITION_HORZ_4"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"9"}),(0,r.jsx)(n.td,{children:"PARTITION_VERT_4"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 2. Type of Block partition"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Partition Block size"}),(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Partition Block size"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"BLOCK_4X4"}),(0,r.jsx)(n.td,{children:"12"}),(0,r.jsx)(n.td,{children:"BLOCK_64X64"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"BLOCK_4X8"}),(0,r.jsx)(n.td,{children:"13"}),(0,r.jsx)(n.td,{children:"BLOCK_64X128"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"BLOCK_8X4"}),(0,r.jsx)(n.td,{children:"14"}),(0,r.jsx)(n.td,{children:"BLOCK_128X64"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"BLOCK_8X8"}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"BLOCK_128X128"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"BLOCK_8X16"}),(0,r.jsx)(n.td,{children:"16"}),(0,r.jsx)(n.td,{children:"BLOCK_4X16"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"BLOCK_16X8"}),(0,r.jsx)(n.td,{children:"17"}),(0,r.jsx)(n.td,{children:"BLOCK_16X4"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6"}),(0,r.jsx)(n.td,{children:"BLOCK_16X16"}),(0,r.jsx)(n.td,{children:"18"}),(0,r.jsx)(n.td,{children:"BLOCK_8X32"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"BLOCK_16X32"}),(0,r.jsx)(n.td,{children:"19"}),(0,r.jsx)(n.td,{children:"BLOCK_32X8"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"8"}),(0,r.jsx)(n.td,{children:"BLOCK_32X16"}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"BLOCK_16X64"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"9"}),(0,r.jsx)(n.td,{children:"BLOCK_32X32"}),(0,r.jsx)(n.td,{children:"21"}),(0,r.jsx)(n.td,{children:"BLOCK_64X16"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"BLOCK_32X64"}),(0,r.jsx)(n.td,{children:"22"}),(0,r.jsx)(n.td,{children:"BLOCK_32X128"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"11"}),(0,r.jsx)(n.td,{children:"BLOCK_64X32"}),(0,r.jsx)(n.td,{children:"23"}),(0,r.jsx)(n.td,{children:"BLOCK_128X32"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 3. Size of Block Partition"}),"\n",(0,r.jsx)(n.h3,{id:"basic-transform-block",children:"Basic Transform Block"}),"\n",(0,r.jsx)(n.p,{children:"Both square and rectangle transform block size is supported in AV1. There are\ntotal 19 transform block size."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"TxSize"}),(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"TxSize"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"TX_4X4"}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"TX_32X16"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"TX_8X8"}),(0,r.jsx)(n.td,{children:"11"}),(0,r.jsx)(n.td,{children:"TX_32X64"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"TX_16X16"}),(0,r.jsx)(n.td,{children:"12"}),(0,r.jsx)(n.td,{children:"TX_64X32"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"TX_32X32"}),(0,r.jsx)(n.td,{children:"13"}),(0,r.jsx)(n.td,{children:"TX_4X16"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"TX_64X64"}),(0,r.jsx)(n.td,{children:"14"}),(0,r.jsx)(n.td,{children:"TX_16X4"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"TX_4X8"}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"TX_8X32"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6"}),(0,r.jsx)(n.td,{children:"TX_8X4"}),(0,r.jsx)(n.td,{children:"16"}),(0,r.jsx)(n.td,{children:"TX_32X8"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"TX_8X16"}),(0,r.jsx)(n.td,{children:"17"}),(0,r.jsx)(n.td,{children:"TX_16X64"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"8"}),(0,r.jsx)(n.td,{children:"TX_16X8"}),(0,r.jsx)(n.td,{children:"18"}),(0,r.jsx)(n.td,{children:"TX_64X16"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"9"}),(0,r.jsx)(n.td,{children:"TX_16X32"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{})]})]})]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"Table 4. Size of Transform Block"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"intra-prediction",children:"Intra Prediction"}),"\n",(0,r.jsx)(n.p,{children:"Intra Prediction in AV1 expends largely compared to VP9. Here is snapshot of\nIntra Mode."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Intra mode"}),(0,r.jsx)(n.th,{children:"AV1"}),(0,r.jsx)(n.th,{children:"VP9"}),(0,r.jsx)(n.th,{children:"Comments"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"DC_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"V_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"AV1 support 7 kind of mode based on this mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"H_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"AV1 support 7 kind of mode based on this mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"D45_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"AV1 support 7 kind of mode based on this mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"D135_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"AV1 support 7 kind of mode based on this mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"D113_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"AV1 support 7 kind of mode based on this mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6"}),(0,r.jsx)(n.td,{children:"D157_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"AV1 support 7 kind of mode based on this mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"D203_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"AV1 support 7 kind of mode based on this mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"8"}),(0,r.jsx)(n.td,{children:"D67_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"AV1 support 7 kind of mode based on this mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"9"}),(0,r.jsx)(n.td,{children:"SMOOTH_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"SMOOTH_V_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"11"}),(0,r.jsx)(n.td,{children:"SMOOTH_H_PRED"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"12"}),(0,r.jsx)(n.td,{children:"TM_PRED(PAETH_PRED)"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"AV1 replace TM_PRED with PAETH_PRED"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"13"}),(0,r.jsx)(n.td,{children:"Palette Mode"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 5. Summary of Intra Mode between AV1 and VP9"}),"\n",(0,r.jsx)(n.h3,{id:"directional-intra-prediction-mode",children:"Directional Intra Prediction Mode"}),"\n",(0,r.jsx)(n.p,{children:"VP9 only supports 8 directional intra prediction modes: D45_PRED, D63_PRED,\nH_PRED, D117_PRED, D135_PRED, D153_PRED, V_PRED, D207_PRED. These modes\ncorrespond to prediction angles of 45, 63, 90, 117, 135, 153, 180, and 207\ndegrees, respectively."}),"\n",(0,r.jsx)(n.p,{children:"To improve intra coding efficiency, more prediction angle options are added to\nAV1. The prediction angle is calculated as the following:"}),"\n",(0,r.jsx)(n.p,{children:"Prediction angle = nominal_angle + (angle_delta * angle_step),"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"nominal_angle"}),(0,r.jsx)(n.th,{children:"angle_step"}),(0,r.jsx)(n.th,{children:"angle_delta"}),(0,r.jsx)(n.th,{children:"Total number of angles"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"45, 63, 90, 117, 135, 153, 180, 207"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"[-3, +3]"}),(0,r.jsx)(n.td,{children:"8*7=56"})]})})]}),"\n",(0,r.jsx)(n.p,{children:"Table 6. Finer of Intra Mode"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"norminal_angle is determined by the prediction mode, and is the same as VP9;"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"angle_delta is in a predefined range and angle_step is a predefined value.\nIn current configuration, angle_delta is in the range of [-3, +3] and\nangle_step is 3. These settings are selected experimentally."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"The total number of supported prediction angles is therefore increased from\n8 to 8 * 7 = 56."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"smooth-mode",children:"Smooth Mode"}),"\n",(0,r.jsx)(n.p,{children:"It is a Non- Directional Intra Prediction mode. VP9 has 2 non-directional intra\nprediction modes: DC_PRED and TM_PRED. AV1 expands on this by adding 3 new\nsmooth prediction modes: SMOOTH_PRED, SMOOTH_V_PRED and SMOOTH_H_PRED. The new\nmodes work as follows:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Mode"}),(0,r.jsx)(n.th,{children:"Comments"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SMOOTH_PRED"}),(0,r.jsx)(n.td,{children:"Useful for predicting blocks that have a smooth gradient. It works as follows: estimate the pixels on the rightmost column with the value of the last pixel in top row, and estimate the pixels in the last row of the current block using the last pixel in left column. Then calculate the rest of the pixels by an average of quadratic interpolation in vertical and horizontal directions, based on distance of the pixel from the predicted pixels."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SMOOTH_V_PRED"}),(0,r.jsx)(n.td,{children:"Similar to SMOOTH_PRED, but uses quadratic interpolation only in the vertical direction"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SMOOTH_H_PRED"}),(0,r.jsx)(n.td,{children:"Similar to SMOOTH_PRED, but uses quadratic interpolation only in the horizontal direction"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 7. Smooth mode of Intra mode"}),"\n",(0,r.jsx)(n.h3,{id:"paeth-mode",children:"Paeth Mode"}),"\n",(0,r.jsx)(n.p,{children:"It is a Non- Directional Intra Prediction mode. The new prediction mode\nPAETH_PRED replaces the existing mode TM_PRED."}),"\n",(0,r.jsx)(n.p,{children:"TM_PRED: Predictor(TM) = left + top \u2013 top_left"}),"\n",(0,r.jsx)(n.p,{children:"PAETH_PRED: Predictor (PAETH) = argmin |x- Predictor(TM)|"}),"\n",(0,r.jsx)(n.p,{children:"The idea is to find out the One of left, top, top_left closest in value to\nPredictor(TM)."}),"\n",(0,r.jsx)(n.h3,{id:"palette-mode",children:"Palette Mode"}),"\n",(0,r.jsx)(n.p,{children:"Sometimes, given intra block can be approximated by a block with small number of\nunique colors. This is especially true for artificial videos like\nscreen-capture, games etc. For such cases, AV1 introduces a new intra coding\nmode called palette mode. This predictor for a block is signaled by storing (i)\na color palette, with 2 to 8 colors, and (ii) color indices into the palette for\nall pixels in the block. The residual pixel values of the block are as usual\ntransformed and quantized before being entropy-coded."}),"\n",(0,r.jsx)(n.p,{children:"Palette mode can be used by both intra-only as well as inter frames. The number\nof base colors determines the trade-off between fidelity and compactness. The\ncolor indices for pixels are obtained by the nearest neighbor method. The color\nindices are encoded using the neighborhood-based context to be as compact as\npossible."}),"\n",(0,r.jsx)(n.p,{children:"Palette Mode is not new. We can see the Palette Mode and Intra block copy in the\nHEVC SCC (Screen Content Coding) extension."}),"\n",(0,r.jsx)(n.h3,{id:"filter-intra-mode",children:"Filter Intra mode"}),"\n",(0,r.jsx)(n.p,{children:"AV1 adopt the new mode to interpolate (intra filter) the reference samples\nbefore prediction. This will reduce the impact of quantization noise. Here is\nthe table to specify the type of intra filtering."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Filter intra type"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"INTRA_DC_PRED"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"INTRA_V_PRED"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"INTRA_H_PRED"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"INTRA_D153_PRED"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"INTRA_TM_PRED"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 8 Type of Intra filter Mode"}),"\n",(0,r.jsx)(n.h3,{id:"intra-block-copy-mode",children:"Intra Block Copy Mode"}),"\n",(0,r.jsx)(n.p,{children:"This tool is very efficient for coding of screen content video in that repeated\npatterns in text and graphics rich content occur frequently within the same\npicture. Having a previously reconstructed block with equal or similar pattern\nas a predictor can effectively reduce the prediction error and therefore improve\ncoding efficiency."}),"\n",(0,r.jsx)(n.p,{children:"In AV1, Intra block copy is only allowed in intra frames. It disables all loop\nfiltering and only integer offsets are allowed in block copy mode."}),"\n",(0,r.jsx)(n.h3,{id:"predict-chroma-from-luma",children:"Predict Chroma from Luma"}),"\n",(0,r.jsx)(n.p,{children:"Chroma from luma (CfL) prediction is a new and promising chroma-only intra\npredictor that models chroma pixels as a linear function of the coincident\nreconstructed luma pixels."}),"\n",(0,r.jsx)(n.h2,{id:"inter-prediction",children:"Inter Prediction"}),"\n",(0,r.jsx)(n.h3,{id:"affinewarped-motion-compensation",children:"Affine/Warped Motion Compensation"}),"\n",(0,r.jsx)(n.p,{children:"Traditional modern codecs, including VP9, use block motion compensation where\nmotion vectors are translational only. This is not sufficient for real video\nwhich often contains complex motion. For example, motion due to camera shake,\npanning and zoom might require transformations that support shearing, scaling,\nrotation and changes in aspect ratio. In AV1, we introduce warped motion\ncompensation implemented as similarity and affine transformations to better\ncapture the diversity of motion that exists in real video. There are two\naffine/warped motion compensation."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Affine Motion Compensation"}),(0,r.jsx)(n.th,{children:"Comments"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Global"}),(0,r.jsx)(n.td,{children:"It is common for videos to contain a global camera motion which is pertinent to an entire inter frame. It is therefore beneficial to transmit a set of motion parameters at the frame level that is applicable to a large number of blocks in the frame. When a frame is encoded, a set of global motion parameters is computed and transmitted between that frame and each reference frame. These parameters may be either translational, similarity or affine motion model. Subsequently, any block in the frame can signal use of the global motion mode with a given reference to create a suitable predictor."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Local"}),(0,r.jsx)(n.td,{children:"Affine motion compensation is also useful to describe complex local object motion. Here, we estimate affine parameters for a single block using the translational motion vectors that are typically conveyed for all inter blocks. Specifically, we estimate an affine or similarity model using the motion vectors from the current block and its causal neighbors which share the same reference frame."})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 9 Affine Motion Compensation"}),"\n",(0,r.jsx)(n.h3,{id:"obmc-overlapped-block-motion-compensation",children:"OBMC (Overlapped Block Motion Compensation)"}),"\n",(0,r.jsx)(n.p,{children:"Motions assigned to surrounding blocks will contribute to predicting a current\nblock, via a well-defined overlapping scheme appropriately designed for advanced\nvariable block-size partitioning frameworks."}),"\n",(0,r.jsx)(n.p,{children:"The OBMC will blend multiple predictors from neighbor blocks. It is not new\nconcept and was proposed and implemented back in the era of h.263. The OBMC was\nproved to largely reduce prediction errors but not adopted by recent codecs due\nto extra complexity in the scenario of hybrid inter/intra variable block size\ncoding. In AV1, a practical overlapping mechanism based on two-stage 1-D\nfiltering is proposed for the advanced partitioning framework to implement\ncausal overlapped block prediction."}),"\n",(0,r.jsx)(n.h3,{id:"sub-pixel-interpolation-filter",children:"Sub-pixel Interpolation Filter"}),"\n",(0,r.jsx)(n.p,{children:"The motion vector used in modern video codecs is allowed to have a fractional\nposition for a better prediction quality. So, an interpolation filter module is\nneeded to generate the prediction block at a fractional position in the\nreference frame. VP9 codec uses a separable interpolation filter to perform\ninter prediction with \u215b motion vector precision. Three filter types, SHARP,\nREGULAR and SMOOTH, in descending order of cutoff frequencies, are provided to\ndeal with various types of noise/distortions that can occur in reference\nframes/blocks. Given a filter type and a motion vector, the interpolation filter\nis performed by two one-dimensional filters, one for horizontal direction and\none for vertical direction."}),"\n",(0,r.jsx)(n.p,{children:"In AV1 codec, dual interpolation filter is introduced on top of the\ninterpolation module inherited from VP9. Dual filter allows each block/frame to\nuse a different interpolation filter type in horizontal and vertical direction.\nUp to 9 types of filter will be applied to the block."}),"\n",(0,r.jsx)(n.p,{children:"This idea is based on the observation that a reference frame/block\u2019s horizontal\nand vertical signals may have distinct frequency characteristics; therefore,\nusing different filter types may produce a better prediction. As before, both\nthe filter types are transmitted in the bitstream on a per block or per frame\nbasis."}),"\n",(0,r.jsx)(n.p,{children:"At the same time AV1 use the high intermediate precision between the horizontal\nand vertical filter. The same high precision before average the predictors with\ncompound mode."}),"\n",(0,r.jsx)(n.h3,{id:"dynamic-mv-reference",children:"Dynamic MV reference"}),"\n",(0,r.jsx)(n.p,{children:"VP9 has two candidates MV in the ref list and 4 type of mode (NEARESTMV, NEARMV,\nNEWMV, and ZEROMV) are used. AV1 support 4 candidate MV and more modes."}),"\n",(0,r.jsx)(n.p,{children:"For single ref mode, AV1 is same as VP9."}),"\n",(0,r.jsx)(n.p,{children:"For compound mode, VP9 restricts motion vectors for a compound predictor to\nshare one motion vector referencing mode, even though they may use different\nreference frames. To add more flexibility, on top of existing four combinations\n(NEAREST_NEARESTMV, NEAR_NEARMV, NEW_NEWMV, ZERO_ZEROMV) in VP9, AV1 supports\nfour more empirically selected combinations: NEAREST_NEWMV, NEW_NEARESTMV,\nNEAR_NEWMV, and NEW_NEARMV."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Ref Mode"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"NEARESTMV"}),(0,r.jsx)(n.td,{children:"single ref mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"NEARMV"}),(0,r.jsx)(n.td,{children:"single ref mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"GLOBALMV(ZEROMV)"}),(0,r.jsx)(n.td,{children:"single ref mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"NEWMV"}),(0,r.jsx)(n.td,{children:"single ref mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"NEAREST_NEARESTMV"}),(0,r.jsx)(n.td,{children:"compound mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"NEAR_NEARMV"}),(0,r.jsx)(n.td,{children:"compound mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6"}),(0,r.jsx)(n.td,{children:"NEAREST_NEWMV"}),(0,r.jsx)(n.td,{children:"compound mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"NEW_NEARESTMV"}),(0,r.jsx)(n.td,{children:"compound mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"8"}),(0,r.jsx)(n.td,{children:"NEAR_NEWMV"}),(0,r.jsx)(n.td,{children:"compound mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"9"}),(0,r.jsx)(n.td,{children:"NEW_NEARMV"}),(0,r.jsx)(n.td,{children:"compound mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"GLOBAL_GLOBALMV(ZERO_ZEROMV)"}),(0,r.jsx)(n.td,{children:"compound mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"11"}),(0,r.jsx)(n.td,{children:"NEW_NEWMV"}),(0,r.jsx)(n.td,{children:"compound mode"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 10 MV mode"}),"\n",(0,r.jsx)(n.h3,{id:"extended-compound-modes",children:"Extended Compound Modes"}),"\n",(0,r.jsx)(n.p,{children:"AV1 Compound mode support both predictors from the same direction and VP9 only\nsupport from the different direction (One forward and one backward reference\nframe). VP9 only support 1/2 weight to blend the two predictor and AV1 support\nmore flexible weight blending."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Compound type"}),(0,r.jsx)(n.th,{children:"Comments"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"COMPOUND_WEDGE"}),(0,r.jsx)(n.td,{children:"Inter-Inter Wedge mode Inter-Intra Wedge mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"COMPOUND_SEG"}),(0,r.jsx)(n.td,{children:"Inter-Inter Compound Segment mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"COMPOUND_AVERAGE"}),(0,r.jsx)(n.td,{children:"(1/2,1/2) weight will be applied to blend the predictors"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"COMPOUND_INTRA"}),(0,r.jsx)(n.td,{children:"Inter-Intra Gradual mode"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"COMPOUND_DISTANCE"}),(0,r.jsx)(n.td,{children:"This process computes weights to be used for blending predictions together based on the expected output times of the reference frames"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 11. Compound type"}),"\n",(0,r.jsx)(n.p,{children:"Here are more details about the Compound Segment Mode:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Inter-Inter Compound Segment mode"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"In many cases, regions in one predictor will contain useful content that is not\npresent in the other. The two inter predictors have a larger pixel difference\ngenerally."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Inter-Inter Wedge mode"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Boundaries of moving objects in a video often separate two regions with distinct\nmotions. Coding these regions with separate motion vector reference combinations\nshould be beneficial; however, finding exact object boundaries is not only\ndifficult, but expensive to communicate in the bitstream. Our approach is to\ndesign a codebook of masks with only a few possible partitioning combinations\nand signaling the codebook index in the bitstream."}),"\n",(0,r.jsx)(n.p,{children:"The AV1 wedge codebook contains partition orientations that are either\nhorizontal, vertical or oblique with slopes: 2, -2, 0.5 and -0.5. The wedge\nprediction mode is used for all square and rectangular blocks, using the 16-ary\nshape codebooks."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Wedge direction"}),(0,r.jsx)(n.th,{children:"Comments"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"WEDGE_HORIZONTAL"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"WEDGE_VERTICAL"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"WEDGE_OBLIQUE27"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"WEDGE_OBLIQUE63"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"WEDGE_OBLIQUE117"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"WEDGE_OBLIQUE153"}),(0,r.jsx)(n.td,{})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 12. Wedge direction"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Inter-Intra Gradual mode"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Decay the weight gradually for the intra from the prediction boundary and\nincrease the weight of inter correspondingly. It support four modes, which\ninclude horizontal mode, vertical mode, DC_PRED, and SMOOTH_PRED."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Inter-Intra Wedge mode"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Blocks cannot always perfectly partition moving objects. For example, occlusion\ncan occur in the middle of a block, it is better to apply different prediction\ntechniques to different contents. Contents that are not occluded in reference\nframe will prefer inter prediction, while newly revealed content could benefit\nmore from intra prediction using local reference."}),"\n",(0,r.jsx)(n.h3,{id:"extended-reference-frame-number",children:"Extended Reference frame Number"}),"\n",(0,r.jsx)(n.p,{children:"Up to 7 reference frames out of 8 in the frame stored buffer are extended to be\nused in the inter mode. The reference frames is allowed to come from the same\nside or different side in the AV1."}),"\n",(0,r.jsx)(n.p,{children:"LAST3_FRAME, LAST2_FRAME and LAST_FRAME are forward references and LAST_FRAME is\nthe near past frame. BWDREF_FRAME is a backward reference, similar to\nALTREF_FRAME."}),"\n",(0,r.jsx)(n.p,{children:"Here is the table to show the reference frame type."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Ref frame Name"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"INTRA_FRAME"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"LAST_FRAME"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"LAST2_FRAME"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"LAST3_FRAME"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"GOLDEN_FRAME"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"BWDREF_FRAME"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6"}),(0,r.jsx)(n.td,{children:"ALTREF2_FRAME"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"ALTREF_FRAME"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 13 Reference frame type"}),"\n",(0,r.jsx)(n.h2,{id:"in-loop-filter",children:"In-loop Filter"}),"\n",(0,r.jsx)(n.p,{children:"Several in-loop tools in AV1 are employed. De-blocking, CDEF and loop\nrestoration are cascaded."}),"\n",(0,r.jsx)(n.h3,{id:"de-blocking-filter",children:"De-blocking filter"}),"\n",(0,r.jsx)(n.p,{children:"AV1 support 4 filter levels per frame and VP9 only has one. Two levels are for\nLuma component (horizontal and vertical levels). The other two levels are for U\nand V component separately. In AV1, filter level is allowed to change superblock\nby superblock."}),"\n",(0,r.jsx)(n.h3,{id:"cdef-constrained-directional-enhancement-filter",children:"CDEF (Constrained Directional Enhancement Filter)"}),"\n",(0,r.jsx)(n.p,{children:"CDEF is the combination of CLPF (Constrained Low Pass Filter) and Deringing\nfilter. The main goal of the in-loop CEDF is to filter the coding artifacts and\nringing while preserving the detail of image. It takes into account the\ndirection of edge and patterns in the image. It is the similar to the SAO of\nHEVC."}),"\n",(0,r.jsx)(n.p,{children:"The CDEF is based on the following observation. The amount of ringing artifacts\nin a coded image tends to be roughly proportional to the quantization step size.\nThe amount of detail is a property of the input image, but the smallest detail\nactually retained in the quantized image tends to also be proportional to the\nquantization step size. For a given quantization step size, the amplitude of the\nringing is generally less than the amplitude of the details."}),"\n",(0,r.jsx)(n.p,{children:"CDEF works as the following steps:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"The frame is divided into filter blocks of 64x64 pixels. Some CDEF\nparameters are signaled at the frame level, and some may be signaled at the\nfilter block level."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"To identify the direction of edge or pattern in each filter block."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"To adaptively filter along the identified direction and to a lesser degree\nalong directions rotated 45 degrees from the identified direction. The\nfilter strengths are signaled explicitly, which allows a high degree of\ncontrol over the blurring."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The main reason for identifying the direction is to align the filter taps along\nthat direction to reduce ringing while preserving the directional edges or\npatterns. CDEF defines primary taps and secondary taps filter. The primary taps\nfollow the direction and the secondary taps form a cross, oriented 45 off the\ndirection. Both primary and secondary taps filter have 8 types."}),"\n",(0,r.jsx)(n.h3,{id:"lr-in-loop-restoration-filter",children:"LR (In-loop Restoration) filter"}),"\n",(0,r.jsx)(n.p,{children:"AV1 employ a set of in-loop image restoration tool after de-blocking to\ngenerally de-noise and enhance the quality of the edge. In-loop restoration\nscheme have two types of filter to remove blur artifacts due to block\nprocessing. One is Wiener Filter. The other is Dual Self-Guided filter. These\ntools are integrated into AV1 with a switchable framework, which trigger the\ndifferent tool in the different image region."}),"\n",(0,r.jsx)(n.h2,{id:"multi-symbol-entropy-coder",children:"Multi-Symbol Entropy Coder"}),"\n",(0,r.jsx)(n.p,{children:"Multi-symbol adaptive arithmetic coding model is adopted in AV1. Both syntax\nelement and coefficient are coded with this model."}),"\n",(0,r.jsx)(n.p,{children:"Most recent video codecs encode information using binary arithmetic coding, such\nas CABA or CAVLC in AVC/HEVC, meaning that each symbol can only take two values.\nThe AV1 entropy encoder come from the Daala range coder and supports up to 16\nvalues per symbol, making it possible to encode fewer symbols. This is\nequivalent to coding up to four binary values in parallel and reduces serial\ndependencies, allowing hardware implementations to use lower clock rates, and\nthus less power."}),"\n",(0,r.jsx)(n.h2,{id:"transform",children:"Transform"}),"\n",(0,r.jsx)(n.h3,{id:"transform-type",children:"Transform type"}),"\n",(0,r.jsx)(n.p,{children:"For AV1, there is a richer set of transforms for coding Inter and Intra\nprediction residues. Inter prediction residues do not have a well-defined\nstructure as in the Intra case, but using a bank of transforms, each adapted to\na specific type of residue profile within the block, is generally helpful."}),"\n",(0,r.jsx)(n.p,{children:"In AV1, four types of transform are used mainly in the horizontal and vertical\ndirection separately. The total 16 different transforms are available."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Transform type"}),(0,r.jsx)(n.th,{children:"Comments"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"DCT"}),(0,r.jsx)(n.td,{children:"Inter and Intra modes continue to make use of DCT."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ADST"}),(0,r.jsx)(n.td,{children:"Asymmetric Discrete Sine Transform"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Flip ADST"}),(0,r.jsx)(n.td,{children:"It applies ADST in reverse order"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"IDTX"}),(0,r.jsx)(n.td,{children:"Identity transform seems to be particularly useful for coding residue with sharp lines and edges. Identity transform is useful for screen content coding"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 14 The Main Transform Type in each of direction"}),"\n",(0,r.jsx)(n.p,{children:"For each small coded block (4x4 or 8x8), it is possible to choose one of up to\n16 different transforms as follows(Detail in Table):"}),"\n",(0,r.jsx)(n.p,{children:"{DCT, ADST, FlipADST, IDTX} horizontal x {DCT, ADST, FlipADST, IDTX} vertical"}),"\n",(0,r.jsx)(n.p,{children:"As block sizes get larger, some of these transforms begin to act similarly.\nThus, a reduced set of transforms is used for 16x16, 32x32 and 64x64 block\nsizes. In the transform selection process for Inter and Intra modes, the encoder\ndoes a search over the entire set of transforms and selects the one that\nproduces the best rate-distortion cost. Once a transform is selected, a\ntransform type symbol from the set of types available at that size is used to\nindicate the actual transform used in the bitstream."}),"\n",(0,r.jsx)(n.p,{children:"There are 6 types of transform sets in the AV1 spec, which specify the transform\ntype of Intra and Inter blocks. The transform sets determine what subset of\ntransform types can be used, according to the following table."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Inter or not"}),(0,r.jsx)(n.th,{children:"Set Number"}),(0,r.jsx)(n.th,{children:"Transform set"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Don't care"}),(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"TX_SET_DCTONLY"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"TX_SET_INTRA_1"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"TX_SET_INTRA_2"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"TX_SET_INTER_1"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"TX_SET_INTER_2"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"TX_SET_INTER_3"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 15 Transform Set in the AV1 spec"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Transform type"}),(0,r.jsx)(n.th,{children:"TX_SET_DCTONLY"}),(0,r.jsx)(n.th,{children:"TX_SET_INTRA_1"}),(0,r.jsx)(n.th,{children:"TX_SET_INTRA_2"}),(0,r.jsx)(n.th,{children:"TX_SET_INTER_1"}),(0,r.jsx)(n.th,{children:"TX_SET_INTER_2"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"DCT_DCT"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ADST_DCT"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"DCT_ADST"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ADST_ADST"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"FLIPADST_DCT"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"DCT_FLIPADST"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"FLIPADST_FLIPADST"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ADST_FLIPADST"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"FLIPADST_ADST"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"IDTX"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"V_DCT"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"H_DCT"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{children:"X"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"V_ADST"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"H_ADST"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"V_FLIPADST"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"H_FLIPADST"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"X"}),(0,r.jsx)(n.td,{})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 16 Detailed Transform type supported in each transform set."}),"\n",(0,r.jsx)(n.h3,{id:"transform-block-shape-and-size",children:"Transform Block Shape and Size"}),"\n",(0,r.jsx)(n.p,{children:"Both square and rectangle shape block are used in AV1. The transform block size\nis less than the partition block size. The block size is very flexible and up to\n64x64 and down to 4x4. Details see the table in the Block section."}),"\n",(0,r.jsx)(n.h2,{id:"tiles",children:"Tiles"}),"\n",(0,r.jsx)(n.p,{children:"AV1 support flexible tiles, which include uniform and non-uniform tile spacing.\nTile area is limited to a maximum 4096x2304. Tiles can be grouped into tile\ngroup and each group can be decoded independently to achieve error resilience.\nLoop filter can be enabled or disabled across tiles."}),"\n",(0,r.jsx)(n.h2,{id:"segment",children:"Segment"}),"\n",(0,r.jsx)(n.p,{children:"Same as VP9, AV1 provides a means of segmenting the image and then applying\nvarious adjustments at the segment level. Up to 8 segments may be specified for\nany given frame. For each of these segments it is possible to specify:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"A quantizer (absolute value or delta)."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"A loop filter strength (absolute value or delta)."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"A prediction reference frame."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"A block skip mode that implies both the use of a (0,0) motion vector and that\nno residual will be coded."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"svc-scalable-video-coding",children:"SVC (Scalable Video Coding)"}),"\n",(0,r.jsx)(n.p,{children:"AV1 support temporal and spatial layer coding. Temporal layer support up to 8\nlayers and spatial layer support up to 3 layers."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Scalability mode"}),(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"Scalability mode"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"SCALABILITY_L1T2"}),(0,r.jsx)(n.td,{children:"8"}),(0,r.jsx)(n.td,{children:"SCALABILITY_L2T2h"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"SCALABILITY_L1T3"}),(0,r.jsx)(n.td,{children:"9"}),(0,r.jsx)(n.td,{children:"SCALABILITY_L2T3h"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"SCALABILITY_L2T1"}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"SCALABILITY_S2T1h"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"SCALABILITY_L2T2"}),(0,r.jsx)(n.td,{children:"11"}),(0,r.jsx)(n.td,{children:"SCALABILITY_S2T2h"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"SCALABILITY_L2T3"}),(0,r.jsx)(n.td,{children:"12"}),(0,r.jsx)(n.td,{children:"SCALABILITY_S2T3h"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"SCALABILITY_S2T1"}),(0,r.jsx)(n.td,{children:"13"}),(0,r.jsx)(n.td,{children:"SCALABILITY_SS"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6"}),(0,r.jsx)(n.td,{children:"SCALABILITY_S2T2"}),(0,r.jsx)(n.td,{children:"14-255"}),(0,r.jsx)(n.td,{children:"reserved"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"SCALABILITY_S2T3"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 17. Temporal and Spatial Mode"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Scalability mode"}),(0,r.jsx)(n.th,{children:"Spatial Layers"}),(0,r.jsx)(n.th,{children:"Resolution Ratio"}),(0,r.jsx)(n.th,{children:"Temporal Layers"}),(0,r.jsx)(n.th,{children:"Inter-layer-dependency"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_L1T2"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_L1T3"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_L2T1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"2:1"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"Yes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_L2T2"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"2:1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"Yes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_L2T3"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"2:1"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"Yes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_S2T1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"2:1"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"No"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_S2T2"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"2:1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"No"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_S2T3"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"2:1"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"No"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_L2T2h"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"1.5:1"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"Yes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_L2T3h"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"1.5:1"}),(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"Yes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SCALABILITY_S2T1h"}),(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"1.5:1"}),(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"No"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 17. Details in the Temporal and Spatial Mode"}),"\n",(0,r.jsx)(n.h2,{id:"other-tools",children:"Other Tools"}),"\n",(0,r.jsx)(n.h3,{id:"quantization-matrices",children:"Quantization Matrices"}),"\n",(0,r.jsx)(n.p,{children:"AV1 support 15 sets of QMs, which are based on the contrast-sensitive functions.\nQMs are applied to a frame based on selectable scaling of its quantization\nlevel, higher level of quantization imply flatter matrices. The matrices become\nflatter as the quantization index value increases (and the quality decreases).\nInter matrices are slightly flatter than intra matrices."}),"\n",(0,r.jsx)(n.h3,{id:"superblock-delta-quantization",children:"Superblock Delta-quantization"}),"\n",(0,r.jsx)(n.p,{children:"AV1 allow the per-superblock changes in quantization parameter to support\nsub-frame rate control. At the same time it support the ROI level rate control\non the top of segmentation level parameter."}),"\n",(0,r.jsx)(n.h3,{id:"obu-open-bitstream-unit",children:"OBU (Open Bitstream Unit)"}),"\n",(0,r.jsx)(n.p,{children:"An AV1 bitstream consists of a number of OBUs that are normally held within a\ncontainer format alongside audio and timing information. Here the new tool OBU\nis introduced in AV1 and it is similar to NAL (Network Abstract Layer) in\nAVC/HEVC spec."}),"\n",(0,r.jsx)(n.p,{children:"The OBU header is similar to the NAL header. In general the total 8 bits are\npresented. The OBU extra 8 bits of extension header is used if temporal and\nspatial layer exist in the bitstream. obu_type is the most important syntax to\ndescribe the type of OBU ."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Index"}),(0,r.jsx)(n.th,{children:"obu_type"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"Reserved"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"OBU_SEQUENCE_HEADER"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"OBU_TD"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"OBU_FRAME_HEADER"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"OBU_TILE_GROUP"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"OBU_METADATA"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6"}),(0,r.jsx)(n.td,{children:"OBU_FRAME"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"7"}),(0,r.jsx)(n.td,{children:"OBU_REDUNDANT_FRAME_HEADER"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"8-14"}),(0,r.jsx)(n.td,{children:"Reserved"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"OBU_PADDING"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Table 18. Type of OBU"}),"\n",(0,r.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://aomediacodec.github.io/av1-spec/av1-spec.pdf",children:"https://aomediacodec.github.io/av1-spec/av1-spec.pdf"})}),"\n"]})]})}function a(e={}){const{wrapper:n}={...(0,d.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>l});var t=i(6540);const r={},d=t.createContext(r);function s(e){const n=t.useContext(d);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(d.Provider,{value:n},e.children)}}}]);